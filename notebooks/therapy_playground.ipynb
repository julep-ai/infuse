{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b8308c-159a-4c63-b55d-501885274b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"EMPTY\"\n",
    "# openai.api_base = \"https://kupid:q3vo94yvq3uiyqvliu@api.julep.ai/v1\"\n",
    "openai.api_base = \"https://demouser1:LYgmsNYE3gts@samantha-1-p5.julep.ai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7abff2-f0c7-4896-9649-36e448777598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\"\"\"\n",
    "Session class holds the current history.\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_COMPLETION_OPTIONS = dict(\n",
    "    max_tokens=120,\n",
    "    stop=[\"<\", \"<|\"],\n",
    "    temperature=0.7,\n",
    "    frequency_penalty=0.5,\n",
    "    repetition_penalty=0.25,\n",
    "    best_of=2,\n",
    ")\n",
    "\n",
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_start|>\"\n",
    "    bos_token = \"<|im_end|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ])\n",
    "\n",
    "    result += '\\n'\n",
    "    \n",
    "    return result\n",
    "\n",
    "class _UNKNOWN: pass\n",
    "UNKNOWN = _UNKNOWN()\n",
    "\n",
    "class Session(BaseModel):\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        \n",
    "    history: list[dict] = []\n",
    "    user: str\n",
    "    assistant: str = \"Samantha\"\n",
    "    asked_close_relationships: bool = False\n",
    "    has_close_relationships: bool | _UNKNOWN = UNKNOWN\n",
    "\n",
    "\n",
    "    # FIXME: API not completing this correctly\n",
    "    def summarize(self):\n",
    "        history_formatted = '\\n'.join([\n",
    "            f\"{message.get('name', message['role'].capitalize())}: {message['content']}\"\n",
    "            for message in self.history\n",
    "            if message[\"role\"] in [\"user\", \"assistant\"]\n",
    "        ])\n",
    "\n",
    "        prompt = (\n",
    "            f\"Summary of the conversation so far between {self.user} and {self.assistant}: \"\n",
    "        )\n",
    "\n",
    "        summary = self.complete(thought_(prompt), store=False, options=dict(temperature=0, best_of=1))\n",
    "\n",
    "        return summary\n",
    "\n",
    "        \n",
    "    def multiple_choice(self, question=None, options=None):\n",
    "        option_keys = list(\"ABCDEFGH\")\n",
    "\n",
    "        prompt = (\n",
    "            f\"Summary of the conversation so far: Samantha has asked Philip about close relationships.\"\n",
    "            f\"\\nQuestion: {question}\"\n",
    "            f\"\\nChoices:\"\n",
    "            f\"\\nA: Yes\"\n",
    "            f\"\\nB: No\"\n",
    "            f\"\\n\"\n",
    "            f\"\\nAnswer: \"\n",
    "        )\n",
    "\n",
    "        return self.complete(thought_(prompt), store=False, use_history=False)\n",
    "        \n",
    "    def pick_question(self):\n",
    "        if not self.asked_close_relationships:\n",
    "            self.asked_close_relationships = True\n",
    "            \n",
    "            return (\n",
    "                \"Who would you say are the important people in your life?\"\n",
    "                \" Do you have close relationships?\"\n",
    "            )\n",
    "\n",
    "        if self.has_close_relationships == True:\n",
    "            return \"Tell me about your closest relationships.\"\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Dont know what to do\")\n",
    "\n",
    "    def next_question(self):\n",
    "        question = self.pick_question()\n",
    "\n",
    "        self.append(thought_(f'I should ask {self.user} \"{question}\" next...'))\n",
    "        return self.complete(me_())\n",
    "\n",
    "    def append(self, message: dict):\n",
    "        match message[\"role\"]:\n",
    "            case \"assistant\": message[\"name\"] = self.assistant\n",
    "            case \"user\": message[\"name\"] = self.user\n",
    "            case _: pass\n",
    "\n",
    "        self.history.append(message)\n",
    "\n",
    "        \n",
    "    # TODO: should add cache here\n",
    "    def complete(self, new_message: dict, options: dict = {}, store: bool = True, use_history: bool = True):\n",
    "        match new_message[\"role\"]:\n",
    "            case \"assistant\": new_message[\"name\"] = self.assistant\n",
    "            case \"user\": new_message[\"name\"] = self.user\n",
    "            case _: pass\n",
    "                \n",
    "        messages = self.history[:] if use_history else []\n",
    "        messages += [{\"continue\": True, \"content\": \"\"} | new_message]\n",
    "        \n",
    "        completion = openai.Completion.create(\n",
    "            model=\"julep-ai/samantha-1-p5\",\n",
    "            # model=\"julep-ai/samantha-33b\",\n",
    "            prompt=make_sections(messages),\n",
    "            **{\n",
    "                **DEFAULT_COMPLETION_OPTIONS,\n",
    "                **options,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        [response, *_] = completion.choices\n",
    "        response = {**new_message, \"content\": response.text.strip()}\n",
    "        # response = {**response.message}\n",
    "        # response[\"content\"] = response[\"content\"].strip()\n",
    "        # response[\"name\"] = new_message[\"name\"]\n",
    "\n",
    "        # if \"continue\" in response:\n",
    "        #     del response[\"continue\"]\n",
    "\n",
    "        # Add to history\n",
    "        if store:\n",
    "            self.history.append(response)\n",
    "\n",
    "        return response\n",
    "        \n",
    "\n",
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system_ = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation_ = lambda content: system_(name=\"situation\", content=content)\n",
    "thought_ = lambda content: system_(name=\"thought\", content=content)\n",
    "information_ = lambda content: system_(name=\"information\", content=content)\n",
    "me_ = lambda content=\"\", name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person_ = lambda content=\"\", name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7ae890-b0c6-49fb-bccf-196b006dd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Philip\"\n",
    "assistant = \"Samantha\"\n",
    "situation_text = f\"{assistant} is talking to {user}. {assistant} is a professional therapist and is helping {user} cope with alcohol addiction\"\n",
    "\n",
    "session = Session(\n",
    "    user=\"Philip\",\n",
    "    history=[\n",
    "        situation_(situation_text),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eba1770-671a-4b37-932a-4bbe5982a055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'name': 'Samantha',\n",
       " 'content': 'How are you doing, Philip?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.append(person_(\"Hello\"))\n",
    "session.complete({\"role\": \"assistant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f03108-a84b-4407-b6c1-4bb093f931d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'thought',\n",
       " 'role': 'system',\n",
       " 'content': 'Philip wants me to help with: \"Generate a list of 5 tips for someone who is trying to quit drinking.\"'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.summarize()\n",
    "# session.multiple_choice(\"Has Samantha asked Philip about his relationships?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccda7ec-51f1-4033-9f51-a2b6a456c7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'thought',\n",
       " 'role': 'system',\n",
       " 'content': 'Philip wants me to help with: \"Generate a list of 5 tips for someone who is trying to quit drinking.\"'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'name': 'thought',\n",
    " 'role': 'system',\n",
    " 'content': 'Philip wants me to help with: \"Generate a list of 5 tips for someone who is trying to quit drinking.\"'}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
