name: julep
version: '3'

services:
  agents:
    env_file:
      - .env
    container_name: agents
    depends_on:
        model:
          condition: service_started
        cozo:
          condition: service_started
        worker:
          condition: service_started
    build: 
      context: agents-api/
      dockerfile: Dockerfile
    ports: 
      - "8080:8080"

  worker:
    env_file:
      - .env
    build:
      context: agents-api/
      dockerfile: Dockerfile.worker
    entrypoint: ["tail", "-f", "/dev/null"]
    depends_on:
        text-embeddings-inference:
          condition: service_started
        temporal:
          condition: service_started


  model:
    env_file:
      - .env
    container_name: model
    build: 
      context: model-api/
      shm_size: '2gb'
    shm_size: '2gb'

    ports: 
      - "8000:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface

  cozo:
    container_name: cozo
    build:
      context: cozo-server/
    ports: 
      - "9070:9070"

  text-embeddings-inference:
    env_file:
      - .env
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-0.6
    ports:
      - "8082:80"
    shm_size: '1gb'

  temporal:
    container_name: temporal
    env_file:
      - .env
    build:
      context: agents-api/
      dockerfile: Dockerfile.temporal
    ports:
      - 7233:7233
    volumes:
      - temporal_data:/home/temporal

volumes:
  model_data:
  temporal_data: