{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/samantha-dev/memory/notebooks/memory_service.ipynb Ячейка 1\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdev-server/home/ubuntu/samantha-dev/memory/notebooks/memory_service.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdev-server/home/ubuntu/samantha-dev/memory/notebooks/memory_service.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmemory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcozo\u001b[39;00m \u001b[39mimport\u001b[39;00m client\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdev-server/home/ubuntu/samantha-dev/memory/notebooks/memory_service.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmemory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membed\u001b[39;00m \u001b[39mimport\u001b[39;00m embed\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdev-server/home/ubuntu/samantha-dev/memory/notebooks/memory_service.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmemory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerate\u001b[39;00m \u001b[39mimport\u001b[39;00m generate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'memory'"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from memory.cozo import client\n",
    "from memory.embed import embed\n",
    "from memory.generate import generate\n",
    "from memory.inserts import *\n",
    "from memory.queries import *\n",
    "from memory.updates import *\n",
    "from memory.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add lru_cache to all queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_id': 'fa9dbe95-9a17-49d9-96d3-764f1970b32f',\n",
       " 'name': 'Samantha',\n",
       " 'about': 'Samantha is a personal assistant, she is very diligent, incredible at her job and really really funny.',\n",
       " 'model': 'julep-ai/samantha-33b'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens: int = 250\n",
    "context_window: int = 2000\n",
    "\n",
    "# 0. `samantha = get_character(samantha_character_id)`\n",
    "\n",
    "samantha_character = client.run(\"\"\"\n",
    "?[\n",
    "    character_id,\n",
    "    name,\n",
    "    about,\n",
    "    model,\n",
    "] := *characters{\n",
    "        character_id,\n",
    "        name,\n",
    "        about,\n",
    "        model,\n",
    "     },\n",
    "     name = \"Samantha\",\n",
    "     is_human = false,\n",
    "\"\"\").iloc[0].to_dict()\n",
    "\n",
    "samantha_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_entry(role: str, name: str, content: str):\n",
    "    return dict(\n",
    "        role=role,\n",
    "        name=name,\n",
    "        content=content,\n",
    "    )\n",
    "    \n",
    "def make_situation(user_name: str, assistant_name: str, situation: str, add_time: bool = False):\n",
    "    # >  `make_situation = lambda data, add_time=False: (`  \n",
    "    # >  `  f\"{samantha.name} is talking to {name}.\"`  \n",
    "    # >  `  + situation`  \n",
    "    # >  `  + f'\\nIt is {human_now()}'`  \n",
    "    # >  `)`  \n",
    "\n",
    "    final_situation = (\n",
    "        f\"{assistant_name} is talking to {user_name}.\"\n",
    "        + f\" {situation.strip()}\"\n",
    "    )\n",
    "    \n",
    "    if add_time:\n",
    "        final_situation += f\"\\n\\nIt is {get_human_date_time()}\"\n",
    "\n",
    "    return final_situation\n",
    "\n",
    "async def respond(\n",
    "    email: str,\n",
    "    vocode_conversation_id: str,\n",
    "    name: Optional[str] = \"Anonymous\",\n",
    "    user_input: Optional[str] = None,\n",
    "    situation: Optional[str] = None,\n",
    "    echo: bool = False,\n",
    "):\n",
    "    # 1. `assert situation ^ user_input`\n",
    "    assert bool(user_input) != bool(situation), \"Must provide either user_input or situation\"\n",
    "    new_session = not bool(user_input)\n",
    "\n",
    "    # 2. `user_data = get_user_by_email(email)`\n",
    "    echo and print(f\"Getting user data for {email}\")\n",
    "    user_data = get_user_by_email(email)\n",
    "\n",
    "    # 3. `if not user_data:`  \n",
    "    #     - `character_data = create_character(name, about, assistant=samantha)`  \n",
    "    #     - `user_data = create_user(email, character_data)`\n",
    "    if not user_data:\n",
    "        about = f\"{name} is a guest user of Julep AI who is here to see what it's like to talk to {assistant_name}.\"\n",
    "\n",
    "        # Create character\n",
    "        echo and print(f\"Creating character for {email}\")\n",
    "        character_data = create_character(name, is_human=True, about=about, model=None)\n",
    "        character_id = character_data[\"character_id\"]\n",
    "\n",
    "        # Create user\n",
    "        echo and print(f\"Creating user for {email}\")\n",
    "        user_data = create_user(email, character_id, samantha_character[\"character_id\"])\n",
    "\n",
    "    character_id = user_data[\"character_id\"]\n",
    "    name = user_data[\"character\"][\"name\"]\n",
    "    about = user_data[\"character\"][\"about\"]\n",
    "\n",
    "    assistant_id = user_data[\"assistant_id\"]\n",
    "    assistant_name = user_data[\"assistant\"][\"name\"]\n",
    "    assistant_about = user_data[\"assistant\"][\"about\"]\n",
    "\n",
    "\n",
    "    # 4. `session = get_session(vocode_conversation_id)`\n",
    "    echo and print(f\"Getting session for {email}\")\n",
    "    session = get_session_by_email(email, vocode_conversation_id)\n",
    "\n",
    "    # 5. `assert situation and not session`\n",
    "    assert bool(situation) ^ bool(session), \"Can only provide either session or situation\"\n",
    "\n",
    "    # 6. `if not session:`\n",
    "    #     - `session = create_session(user_data, vocode_conversation_id, situation)`\n",
    "    #     - `add_session_characters(session, user_data)`\n",
    "    if not session:\n",
    "        echo and print(f\"Creating session for {email}\")\n",
    "        session = create_session(email, vocode_conversation_id, situation)\n",
    "\n",
    "    # 7. `entries = get_session_entries(session_id)`\n",
    "    session_id = session[\"session_id\"]\n",
    "    echo and print(f\"Getting session entries for {session_id}\")\n",
    "\n",
    "    entries = get_session_entries(session_id)\n",
    "\n",
    "    # 8. `{summary} = session`\n",
    "    summary = session[\"summary\"]\n",
    "\n",
    "    # 9. `situation_final = make_situation(user_data, add_time=True)`\n",
    "    situation = situation or session[\"situation\"]\n",
    "    situation_final = make_situation(name, assistant_name, situation, add_time=True)\n",
    "    situation_final = make_entry(\"system\", \"situation\", situation_final)\n",
    "\n",
    "    # 10.  \n",
    "    # >  `info_top = (`  \n",
    "    # >  `  samantha.about`  \n",
    "    # >  `  + user_data.about`  \n",
    "    # >  `  + f'{samantha.name} is very funny but also polite and keeps her responses brief.'`  \n",
    "    # >  `)`  \n",
    "    info_top = (\n",
    "        samantha_character[\"about\"]\n",
    "        + f' {about}'\n",
    "        + f\"{assistant_name} is very funny but also polite and keeps her responses brief.\"\n",
    "    )\n",
    "\n",
    "    info_top = make_entry(\"system\", \"information\", info_top)\n",
    "\n",
    "    # 11. `all_entries = situation_final + info_top + entries`\n",
    "    all_entries = [situation_final, info_top] + entries\n",
    "    user_input_entry = None\n",
    "\n",
    "    if user_input:\n",
    "        user_input_entry = make_entry(\"user\", user_data[\"character\"][\"name\"], user_input)\n",
    "        all_entries.append(user_input_entry)\n",
    "    \n",
    "\n",
    "    # 13. `thought = generate_thought(truncated_entries)`\n",
    "    echo and print(f\"Generating thought for {email}\")\n",
    "\n",
    "    thought_max_tokens = 40\n",
    "\n",
    "    situational_entries = truncate(\n",
    "        all_entries,\n",
    "        max_tokens=context_window - thought_max_tokens,\n",
    "        #\n",
    "        # Keep system entries at the beginning and last 3 entries only\n",
    "        keep_when=lambda x, i: (x[\"role\"] == \"system\" and i == 0) or (i > len(all_entries) - 3),\n",
    "    )\n",
    "\n",
    "    # TODO: Re-enable thoughts when they are working\n",
    "    if new_session:\n",
    "        thought = f\"The call is just starting. I should greet {name}!\"\n",
    "    #\n",
    "    # else:\n",
    "\n",
    "    #     thought_suffix = \"<|section|>thought\\n\"\n",
    "    #     thought = await generate(\n",
    "    #         situational_entries,\n",
    "    #         max_tokens=thought_max_tokens,\n",
    "    #         temperature=0.0,\n",
    "    #         frequency_penalty=0.0,\n",
    "    #         presence_penalty=0.0,\n",
    "    #         best_of=1,\n",
    "    #         prompt_settings=dict(suffix=thought_suffix),\n",
    "    #     )\n",
    "\n",
    "    #     thought = thought[\"choices\"]\n",
    "    #     thought = thought[0][\"text\"] if thought else \"\"\n",
    "            \n",
    "    echo and print(f\"Thought: `{thought}`\")\n",
    "\n",
    "    # 14. `beliefs = get_matching_beliefs(user_data, thought)`\n",
    "    if thought:\n",
    "        thought_entry = make_entry(\"system\", \"thought\", thought)\n",
    "        all_entries.append(thought_entry)\n",
    "\n",
    "    echo and print(f\"Fetching beliefs for {email}\")\n",
    "\n",
    "    beliefs = get_matching_beliefs(situational_entries)\n",
    "\n",
    "    if beliefs:\n",
    "        # 15. `all_entries.append(belief)`\n",
    "        belief_entry = make_entry(\"system\", \"belief\", \" \".join(beliefs))\n",
    "        all_entries.append(belief_entry)\n",
    "\n",
    "    # 16. `truncated_entries = truncate(all_entries)`\n",
    "    truncated_entries = truncate(all_entries, max_tokens=context_window - max_tokens)\n",
    "\n",
    "    # @@ TODO: Add summary\n",
    "    # 17. `if len(truncated_entries) < len(all_entries) and summary:`  \n",
    "    #     - `truncated_entries.insert(summary, 3)`\n",
    "    \n",
    "    # 18. `assistant_output = generate(truncated_entries)`\n",
    "    echo and print(f\"Generating assistant output for {email}\")\n",
    "\n",
    "    utterance_suffix = f\"<|section|>me ({assistant_name})\\n\"\n",
    "    generated = await generate(\n",
    "        truncated_entries,\n",
    "        max_tokens=max_tokens,\n",
    "        prompt_settings=dict(suffix=utterance_suffix),\n",
    "    )\n",
    "\n",
    "    generated = generated[\"choices\"]\n",
    "    assistant_output = \"\"\n",
    "\n",
    "    if generated:\n",
    "        assistant_output = generated[0][\"text\"]\n",
    "    \n",
    "    # 19. `return { assistant_output, session.session_id }`\n",
    "    result = dict(\n",
    "        assistant_output=assistant_output,\n",
    "        session_id=session_id,\n",
    "    )\n",
    "\n",
    "    # @@ TODO\n",
    "    # 20. (In the background)  \n",
    "    #     - `add_entry(session, assistant_output)`\n",
    "    #     - `update_summary(session, truncated_entries[3:])`\n",
    "    #     - `if new_session: add_episodes(session, situation)`\n",
    "    #     - `add_episodes(session, truncated_entries)`\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting user data for diwank@julep.ai\n",
      "Getting session for diwank@julep.ai\n",
      "Creating session for diwank@julep.ai\n",
      "Getting session entries for 4298174e-1991-4911-8d26-4a1737cec339\n",
      "> \u001b[0;32m/tmp/ipykernel_101880/1572173559.py\u001b[0m(107)\u001b[0;36mrespond\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    105 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    106 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 107 \u001b[0;31m    \u001b[0minfo_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"information\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    108 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    109 \u001b[0;31m    \u001b[0;31m# 11. `all_entries = situation_final + info_top + entries`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thought for diwank@julep.ai\n",
      "Thought: `The call is just starting. I should greet Diwank!`\n",
      "Fetching beliefs for diwank@julep.ai\n",
      "3 matching beliefs found for ```situation: Samantha is talking to Diwank. Diwank is sad.\n",
      "\n",
      "It is 12:30PM on Friday, Jul 07 2023\n",
      "information: Samantha is a personal assistant, she is very diligent, incredible at her job and really really funny. Diwank is an AI researcher, entrepreneur and an amazing person.Samantha is very funny but also polite and keeps her responses brief.```\n",
      "Generating assistant output for diwank@julep.ai\n",
      "*** <|section|>situation\n",
      "Samantha is talking to Diwank. Diwank is sad.\n",
      "\n",
      "It is 12:30PM on Friday, Jul 07 2023<|endsection|>\n",
      "<|section|>information\n",
      "Samantha is a personal assistant, she is very diligent, incredible at her job and really really funny. Diwank is an AI researcher, entrepreneur and an amazing person.Samantha is very funny but also polite and keeps her responses brief.<|endsection|>\n",
      "<|section|>thought\n",
      "The call is just starting. I should greet Diwank!<|endsection|>\n",
      "<|section|>belief\n",
      "Diwank has high curiosity and creativity. Diwank is an Inventor. Diwank is comfortable with the unknown and is attracted to the mysterious world.<|endsection|><|section|>me (Samantha)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'assistant_output': 'Hey Diwank, how are you?',\n",
       " 'session_id': '4298174e-1991-4911-8d26-4a1737cec339'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await respond(\n",
    "    email=\"diwank@julep.ai\",\n",
    "    vocode_conversation_id=\"123460\",\n",
    "    situation=\"Diwank is sad.\",\n",
    "    echo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
