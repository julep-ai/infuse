{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67c42d8-363e-4c1c-ab4d-299f6dc14a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"diwank/time-sensitive-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f1d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8bf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda row: dict(\n",
    "    num_tokens=len(\n",
    "        encoding.encode(row[\"context\"] + row[\"question\"] + \"\\n\\n\".join(row[\"targets\"]))\n",
    "    ),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a68670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.99515199999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens = sum(dataset[\"train\"][\"num_tokens\"])\n",
    "gpt35_pricing = 0.002 / 1000\n",
    "gpt35_cost = total_tokens * gpt35_pricing\n",
    "\n",
    "gpt35_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307e1fe4-fb28-453d-bd67-237eb2fe3fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_reasoning(row):\n",
    "    from textwrap import dedent\n",
    "\n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"XXX\"\n",
    "\n",
    "    newline = \"\\n\"\n",
    "    paragraphs = row[\"paragraphs\"]\n",
    "    question = row[\"question\"]\n",
    "    targets = row[\"targets\"]\n",
    "    answer = \", \".join(targets)\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"## {p['title']}{newline}{p['text']}\" for p in paragraphs\n",
    "    ])\n",
    "\n",
    "    INSTRUCTION = f\"\"\"\\\n",
    "You are given a context and a \"temporal\" question that probes dates and times mentioned in the context. You are also given the correct answer along with it.\n",
    "Your task is to write a chain of reasoning that leads to the correct answer. Think step by step and write down your reasoning in detail. Only focus on the \"temporal\" reasoning and not the answer itself.\n",
    "\n",
    "Context\n",
    "=======\n",
    "{context}\n",
    "\n",
    "Q & A\n",
    "=====\n",
    "Q: {question}\n",
    "A: {answer}\n",
    "\n",
    "Reasoning\n",
    "=========\n",
    "- \n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(8))\n",
    "    def completion_with_backoff(prompt):\n",
    "\n",
    "        completion = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=256,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].text\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(INSTRUCTION)\n",
    "    reasoning = \"- \" + completion\n",
    "\n",
    "    return dict(\n",
    "        question=question,\n",
    "        answer=answer,\n",
    "        reasoning=reasoning,\n",
    "        context=context,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4755d3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3497"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dataset[\"train\"][\"num_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "840e1a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b06174226045b49b8261eff337c453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb972e268cf4a61953663db9f836bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42346ba7bd143cda836a1385e93b7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda row: row[\"num_tokens\"] < 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8143fdfb-6146-4c2b-9ae3-0af489e1f280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e31d0d6849d4b64a6a994480d37e994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=75):   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c236e2e353f4051890ac961b08cd63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=75):   0%|          | 0/12378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad6cc610813427b8c33298105c8890c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=75):   0%|          | 0/2570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(get_reasoning, num_proc=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb0dc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"question\", \"answer\", \"reasoning\", \"context\"}\n",
    "columns_to_remove = list(set(dataset[\"train\"].column_names) - columns_to_keep)\n",
    "dataset = dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35e08c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a29fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chatml(row):\n",
    "    question = row[\"question\"]\n",
    "    answer = row[\"answer\"]\n",
    "    context = row[\"context\"]\n",
    "    reasoning = row[\"reasoning\"]\n",
    "    newline = \"\\n\"\n",
    "    \n",
    "    # Turn into chatml\n",
    "    chatml = [\n",
    "        situation(\"A user is talking to an AI assistant. They are discussing an article that the user has read.\"),\n",
    "        person(f\"Based on the article below, can you answer the following question:{newline}{question}\", name=\"User\"),\n",
    "        information(context),\n",
    "        thought(f\"Let's think step by step:{newline}{reasoning}\"),\n",
    "        me(f\"The correct answer is: {answer}\", name=\"AI Assistant\"),\n",
    "    ]\n",
    "\n",
    "    return dict(chatml=chatml)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca6a3cae-70d9-4882-8a02-4c686450a709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8645688da6e14a4898214b521ca571ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b6320e48a49aba6f47b0b15e8ec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839987d4ab4245feae213d52c7f95f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(to_chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca13a302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e150bb3a9d34a59a6f6e65178b36051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc91bddb6c1405696ee0df4ac6341a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3659127afd5a4797b177ed5d908776ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bb971228864f1f93338aee387c2a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1f1b13c181434f9e10e073f7491946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebfced54aae426e93fe2b23a51bd692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/time_sensitive_qa-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e2819-fddf-4465-b8e2-f2bca708f392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
