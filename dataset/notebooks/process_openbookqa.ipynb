{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d6484d-a15a-47dc-8d1f-58d6e9c08869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset openbookqa/additional to /home/diwank/.cache/huggingface/datasets/openbookqa/additional/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c835048bb294e8496a7f9299e0194c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4957 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset openbookqa downloaded and prepared to /home/diwank/.cache/huggingface/datasets/openbookqa/additional/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b09412312754879b11c9996d68bd027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "openbookqa = load_dataset(\"openbookqa\", \"additional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38dc3a8-59f5-446a-9d61-e92228a7fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/openbookqa/additional/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f/cache-c804c802d4277e46.arrow\n",
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/openbookqa/additional/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f/cache-18f033fba0983f6b.arrow\n",
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/openbookqa/additional/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f/cache-a8cb5bdc97d31241.arrow\n"
     ]
    }
   ],
   "source": [
    "openbookqa_subset = openbookqa.filter(lambda row: (\n",
    "    row[\"humanScore\"] >= 1.0\n",
    "    and row[\"clarity\"] >= 1.5\n",
    "    and row[\"question_stem\"].strip().endswith('?')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a0d23-42bb-40f8-ad08-ccb93c5ac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "def to_chatml(row):\n",
    "    question = row[\"question_stem\"]\n",
    "    choices = row[\"choices\"]\n",
    "    fact = row[\"fact1\"]\n",
    "    answer_key = row[\"answerKey\"]\n",
    "\n",
    "    choices = \"\\n\".join([\n",
    "        f\"{label}) {text}\"\n",
    "        for label, text\n",
    "        in zip(choices[\"label\"], choices[\"text\"])\n",
    "    ])\n",
    "\n",
    "    siutation_text = (\n",
    "        \"A person is talking to an intelligent AI assistant.\"\n",
    "        \" The person is quizzing the AI assistant on miscellaneous questions\"\n",
    "        \" in a multiple choice format.\"\n",
    "        \" The assistant first thinks carefully about the question and lays down its reasoning.\"\n",
    "        \" Then answers the question with the correct choice key and the right answer.\"\n",
    "    )\n",
    "    \n",
    "    mcq = f\"Question: {question}\\nChoices:\\n{choices}\"\n",
    "    thought_text\n",
    "    answer_text \n",
    "    \n",
    "    chatml = [\n",
    "        situation(),\n",
    "        person(),\n",
    "        thought(),\n",
    "        me(),\n",
    "    ]\n",
    "    \n",
    "    return dict(chatml=chatml)\n",
    "\n",
    "openbookqa_chatml = openbookqa_subset.map(\n",
    "    to_chatml\n",
    ").remove_columns(openbookqa_subset.column_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
