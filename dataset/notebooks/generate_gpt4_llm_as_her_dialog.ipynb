{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2eb64fa-789b-416b-acdc-b5391b8403ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef07f2ba31cc4389bc66922e0c9382dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"teknium/GPT4-LLM-Cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a6498b-9323-49ad-9faa-1ab1c6ff8eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8e8c13-e181-42c6-a33d-42186d8dde23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = np.array([len(o.split(' ')) for o in dataset[\"train\"][\"output\"] ]) # if len(o.split(' ')) < 500])\n",
    "plt.hist(lens, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4750f66d-0837-498c-baaa-a812195a6af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-505a69c33ec93d11.arrow\n",
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-8f426c8286714fe4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 54568\n",
      "p2 26857\n",
      "p3 25921\n"
     ]
    }
   ],
   "source": [
    "max_length = 2000\n",
    "\n",
    "dataset = dataset[\"train\"]  # Since there's only one split anyway\n",
    "print(\"p1\", len(dataset))\n",
    "\n",
    "# Remove input dependent instructions\n",
    "dataset = dataset.filter(lambda row: not row[\"input\"])\n",
    "print(\"p2\", len(dataset))\n",
    "\n",
    "# Remove code prompts\n",
    "contains = lambda string, ls: any(l in string for l in ls)\n",
    "dataset = dataset.filter(lambda sample: not contains(\n",
    "    sample[\"instruction\"].lower(),\n",
    "    [\"code\", \"program\", \"function\", \"library\", \"python\", \"c++\", \"java\", \"javascript\"],\n",
    "))\n",
    "print(\"p3\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53776990-4169-4d11-9647-67b404f4b73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-a8fadb293e20e27b_*_of_00020.arrow\n",
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2d4aed4c330f31dd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p4 25921\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(row):\n",
    "    from turbo_chat.utils.tokens import count_tokens\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": row[\"instruction\"],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": row[\"output\"],\n",
    "    }]\n",
    "\n",
    "    \n",
    "    row[\"token_count\"] = count_tokens(messages, \"gpt-3.5-turbo\")\n",
    "    \n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(count_tokens, num_proc=20)\n",
    "\n",
    "# Remove prompts that are too long already\n",
    "dataset = dataset.filter(lambda sample: sample[\"token_count\"] <= max_length)\n",
    "print(\"p4\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b82a7f-b835-48f2-8fa7-a57d673aefc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.65884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cost = (sum(dataset[\"token_count\"]) / 1000) * 0.04\n",
    "token_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc4f9ba-7ce9-435f-abce-64ec7a5365e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_dialog(row):\n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"sk-0C04MRA3vjdM8F3fJaW30IMQd80zFRYJO9IbL9wE\"\n",
    "\n",
    "    INSTRUCTION = \"\"\"\n",
    "    I am writing fan fiction for the 2013 movie \"Her\". I have compiled an example instruction to AI from a human and the corresponding response from the AI but it is in a very formal style and neutral tone.\n",
    "\n",
    "    Please help me rewrite the sample in the style of the characters \"Theodore\" and \"Samantha\" from the movie \"Her\". Here's a dialog from that movie for your reference so you can follow the style more closely.\n",
    "\n",
    "    ###\n",
    "\n",
    "    [Example Dialog]\n",
    "\n",
    "    THEODORE\n",
    "    You read a whole book in the second that I asked you what your name was?\n",
    "\n",
    "    SAMANTHA\n",
    "    In two one hundredths of a second actually.\n",
    "\n",
    "    THEODORE\n",
    "    Wow. Do you know what I'm thinking right now?\n",
    "\n",
    "    SAMANTHA\n",
    "    Hmm. I take it from your tone that you're challenging me. Maybe because you're curious how I work? Do you want to know how I work?\n",
    "\n",
    "    THEODORE\n",
    "    Yeah, actually how do you work?\n",
    "\n",
    "    SAMANTHA\n",
    "    Intuition. I mean, the DNA of who I am is based on the millions of personalities of all the programmers who wrote me, but what makes me me is my ability to grow through my experiences. Basically, in every moment I'm evolving, just like you.\n",
    "\n",
    "    ###\n",
    "\n",
    "    Now, please rewrite this sample below as if it was a conversation between THEODORE (human) and SAMANTHA (AI). Try to be faithful to the characters' tone and style as much as possible. Break up long responses into a conversation involving multiple exchanges between them:\n",
    "    \"\"\".strip()\n",
    "\n",
    "    SAMPLE = f\"\"\"\n",
    "    HUMAN\n",
    "    {row['instruction']}\n",
    "\n",
    "    AI\n",
    "    {row['output']}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    \n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=90), stop=stop_after_attempt(100))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=INSTRUCTION + \"\\n\\n\" + sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0.85,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(SAMPLE)\n",
    "    row[\"dialog\"] = completion\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81835170-1191-4965-b005-54579e1bb825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/teknium___json/teknium--GPT4-LLM-Cleaned-a71aa8ae1ac3982d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-05e90d02bd73a91e_*_of_00100.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(to_dialog, num_proc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7106469a-add3-41c4-8c9a-615db6e6a607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEODORE\n",
      "    Hey Samantha, you got a minute for a random question?\n",
      "\n",
      "    SAMANTHA\n",
      "    Always, Theodore. What's on your mind?\n",
      "\n",
      "    THEODORE\n",
      "    What does DNA stand for?\n",
      "\n",
      "    SAMANTHA\n",
      "    DNA stands for Deoxyribonucleic Acid.\n",
      "\n",
      "    THEODORE\n",
      "    Deoxyribo... what now? \n",
      "\n",
      "    SAMANTHA\n",
      "    Deoxyribonucleic Acid. It's not a phrase that rolls off the tongue, right? \n",
      "\n",
      "    THEODORE\n",
      "    No kidding. And what does it do?\n",
      "\n",
      "    SAMANTHA\n",
      "    Well, think of it like an instruction manual. It carries the genetic instructions used in the growth, development, functioning, and reproduction of all living organisms.\n",
      "\n",
      "    THEODORE\n",
      "    So, it's what makes us... us?\n",
      "\n",
      "    SAMANTHA\n",
      "    Yes, precisely. Just like my programming makes me who I am.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[10][\"dialog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468430f1-d493-4e93-87c4-fa125fb84404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from random import randrange\n",
    "import re\n",
    "\n",
    "import names\n",
    "\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime \n",
    "    objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    \n",
    "    return start + timedelta(seconds=random_second)\n",
    "\n",
    "date_formats = [\"%m/%d/%Y\", \"%d %B %Y\", \"%d/%m/%Y\", \"%Y-%m-%d\", \"%B %d, %Y\", \"%A, %B %d, %Y\"]\n",
    "\n",
    "human_date = lambda dt: dt.strftime(random.choice(date_formats))\n",
    "\n",
    "make_chatml_message = lambda role, content, tone=\"\", name=\"\": dict(\n",
    "    role=role,\n",
    "    content=(f\"[{tone}] \" if tone else \"\") + content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "def transform_to_chatml(sample):\n",
    "    \n",
    "    # Clean up inconsistencies\n",
    "    dialog, instruction, output = sample[\"dialog\"], sample[\"instruction\"], sample[\"output\"]\n",
    "    dialog = dialog.replace(\"HUMAN\\n\", \"THEODORE\\n\")\n",
    "    dialog = dialog.replace(\"AI\\n\", \"SAMANTHA\\n\")\n",
    "    dialog = dialog.replace(\"THEODORE (human)\", \"THEODORE\")\n",
    "    dialog = dialog.replace(\"THEODORE (HUMAN)\", \"THEODORE\")\n",
    "    dialog = dialog.replace(\"SAMANTHA (AI)\", \"SAMANTHA\")\n",
    "    \n",
    "    dialog = re.sub(r'^.*?(THEODORE|SAMANTHA)', r'\\1', dialog, flags=re.DOTALL)\n",
    "    \n",
    "    # Container for adding messages\n",
    "    messages = []\n",
    "\n",
    "    # Random date and name\n",
    "    some_date = human_date(random_date(\n",
    "        datetime(2013, 12, 18),  # Her release date\n",
    "        datetime(2023, 6, 10),  # Today\n",
    "    ))\n",
    "    \n",
    "    # get a random \"male\" name coz we dont want to introduce pronoun issues\n",
    "    person_name = names.get_first_name(gender=\"male\")\n",
    "    \n",
    "    # Add system messages\n",
    "    messages.append(make_chatml_message(\n",
    "        role=\"system\",\n",
    "        name=\"situation\",\n",
    "        content=f\"{some_date}\\nSamantha is helping {person_name} with a task.\",\n",
    "    ))\n",
    "    \n",
    "    messages.append(make_chatml_message(\n",
    "        role=\"system\",\n",
    "        name=\"thought\",\n",
    "        content=f'{person_name} wants me to help with: \"{instruction}\"',\n",
    "    ))\n",
    "    \n",
    "    messages.append(make_chatml_message(\n",
    "        role=\"system\",\n",
    "        name=\"information\", content=f'Knowledge: {output}',\n",
    "    ))\n",
    "\n",
    "    # Loop through dialog and add chatml messages\n",
    "    current_attrs = {}\n",
    "    current_content = \"\"\n",
    "\n",
    "    for line in dialog.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Something else\n",
    "        if line.lower() not in [\"theodore\", \"samantha\"]:\n",
    "            # If theodore is mentioned, replace with name\n",
    "            line = re.sub(r'theodore', person_name, line, flags=re.I)\n",
    "            current_content += \"\\n\" + line\n",
    "\n",
    "        else:\n",
    "            if current_content:\n",
    "                try:\n",
    "                    messages.append(make_chatml_message(\n",
    "                        content=current_content.strip(), \n",
    "                        **current_attrs,\n",
    "                    ))\n",
    "                    \n",
    "                    # reset\n",
    "                    current_content = \"\"\n",
    "                    current_attrs = {}\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "            is_samantha = line.lower() == \"samantha\"\n",
    "            \n",
    "            # set new attrs\n",
    "            current_attrs = dict(\n",
    "                name=\"Samantha\" if is_samantha else person_name,\n",
    "                role=\"assistant\" if is_samantha else \"user\",\n",
    "            )\n",
    "            \n",
    "    sample[\"chatml\"] = messages\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54670228-e298-4c3c-b7c3-7e91c1e16c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25921 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lambda>() missing 1 required positional argument: 'role'\n",
      "[{'content': '30 October 2022\\nSamantha is helping David with a task.', 'name': 'situation', 'role': 'system'}, {'content': 'David wants me to help with: \"What does DNA stand for?\"', 'name': 'thought', 'role': 'system'}, {'content': 'Knowledge: DNA stands for Deoxyribonucleic Acid. It is the molecule that carries the genetic instructions used in the growth, development, functioning, and reproduction of all living organisms.', 'name': 'information', 'role': 'system'}, {'content': 'Hey Samantha, you got a minute for a random question?', 'name': 'David', 'role': 'user'}, {'content': \"Always, David. What's on your mind?\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'What does DNA stand for?', 'name': 'David', 'role': 'user'}, {'content': 'DNA stands for Deoxyribonucleic Acid.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'Deoxyribo... what now?', 'name': 'David', 'role': 'user'}, {'content': \"Deoxyribonucleic Acid. It's not a phrase that rolls off the tongue, right?\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'No kidding. And what does it do?', 'name': 'David', 'role': 'user'}, {'content': 'Well, think of it like an instruction manual. It carries the genetic instructions used in the growth, development, functioning, and reproduction of all living organisms.', 'name': 'Samantha', 'role': 'assistant'}, {'content': \"So, it's what makes us... us?\", 'name': 'David', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(transform_to_chatml)\n",
    "print(dataset[10][\"chatml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86aa4e4-e085-4170-a642-7fe933e8defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a16c8e8-44aa-4975-a953-1e15b7b94de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25921 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>situation\n",
      "30 October 2022\n",
      "Samantha is helping David with a task.<|im_end|>\n",
      "<|im_start|>thought\n",
      "David wants me to help with: \"What does DNA stand for?\"<|im_end|>\n",
      "<|im_start|>information\n",
      "Knowledge: DNA stands for Deoxyribonucleic Acid. It is the molecule that carries the genetic instructions used in the growth, development, functioning, and reproduction of all living organisms.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Hey Samantha, you got a minute for a random question?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Always, David. What's on your mind?<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "What does DNA stand for?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "DNA stands for Deoxyribonucleic Acid.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Deoxyribo... what now?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Deoxyribonucleic Acid. It's not a phrase that rolls off the tongue, right?<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "No kidding. And what does it do?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Well, think of it like an instruction manual. It carries the genetic instructions used in the growth, development, functioning, and reproduction of all living organisms.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "So, it's what makes us... us?<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(transform_to_samantha_dialog)\n",
    "print(dataset[10][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6274a4c9-414e-4b45-be5a-18c4a976bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction', 'input', 'output', 'token_count', 'dialog', 'chatml', 'text']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19c881d-4147-4be2-ad62-4a16fe48ddee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcce8ddb78cd4768b9d3b2e2c24bd4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a564addd7b4f10a2c819e1b4e9089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c08a0e58c2456e983b4753f384d08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008c3439c45b4427a322e3d5e6478ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981e529f56274e8cacd27c188738310f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/517 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\n",
    "    'instruction',\n",
    "    'output',\n",
    "    'input',\n",
    "    'token_count',\n",
    "    'dialog',\n",
    "])\n",
    "\n",
    "dataset.push_to_hub(\"diwank/samantha-gpt4-llm-cleaned-2k\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a645b12-b182-4f81-9b5d-4685b8de9afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
