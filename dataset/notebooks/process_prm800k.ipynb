{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7c9c75-4699-4ec4-acfd-eef612055338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4908706d-1cc4-40f5-bd6b-d7bbdeb63e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/diwank/.cache/huggingface/datasets/sl-alex___parquet/sl-alex--openai-prm800k-stepwise-best-3114ba6fda88bc06/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cf53f639094e698bda5524c25be4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"sl-alex/openai-prm800k-stepwise-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be4c71c-e2d7-4434-8b16-99086248a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/sl-alex___parquet/sl-alex--openai-prm800k-stepwise-best-3114ba6fda88bc06/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-bd235134cc22d066.arrow\n",
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/sl-alex___parquet/sl-alex--openai-prm800k-stepwise-best-3114ba6fda88bc06/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3500f361afa59527.arrow\n"
     ]
    }
   ],
   "source": [
    "# Remove intermediate stuff because final answer has all of them anyway\n",
    "dataset = dataset.filter(lambda row: row[\"answer\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "610d26d6-676a-47a2-8f12-9056646f4842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2199, 12419)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stuff with mathml and special symbols\n",
    "filtered_dataset = dataset.filter(lambda row: (\n",
    "    '$' not in row[\"instruction\"]\n",
    "    and '\\\\' not in row[\"instruction\"]\n",
    "    and all([\n",
    "        ('$' not in r\n",
    "        and '\\\\' not in r)\n",
    "        for r in row[\"responses\"]\n",
    "    ])\n",
    "))\n",
    "\n",
    "len(filtered_dataset[\"train\"]), len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a26955d-322a-49d2-90a1-5cac0b010a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatml utils\n",
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff99d6f4-6908-427d-8312-b3f1e9da1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Joe is studying a bacteria population.  There are 20 bacteria present at 3:00 p.m. and the population doubles every 3 minutes.  Assuming none of the bacteria die, how many bacteria are present at 3:15 p.m. the same day?',\n",
       " 'responses': ['We first need to find out how many minutes have passed since 3:00 p.m.',\n",
       "  'Yes, it is now 3:15 p.m., so 15 minutes have passed.',\n",
       "  'Right. And we are told that the bacteria population doubles every 3 minutes.',\n",
       "  'That means that at 3:03 p.m., there were 40 bacteria. And at 3:06 p.m., there were 80 bacteria.',\n",
       "  'We can keep going until we reach 3:15 p.m.',\n",
       "  'Right. So at 3:09 p.m., there were 160 bacteria. And at 3:12 p.m., there were 320 bacteria.',\n",
       "  'Finally, at 3:15 p.m., there were 640 bacteria.'],\n",
       " 'next_response': 'So there are 640 bacteria present at 3:15 p.m.',\n",
       " 'answer': '640',\n",
       " 'is_human_response': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset[\"train\"][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fe30dc6-fc36-4fdf-a388-61231ba0a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chatml(row):\n",
    "    instruction = row[\"instruction\"]\n",
    "    responses = row[\"responses\"][:]\n",
    "    answer = row[\"answer\"]\n",
    "\n",
    "    answer = f'The answer is \"{answer}\".'\n",
    "\n",
    "    thoughts_text = \"\\n\".join([\n",
    "        f\"{i+1}. {response}\"\n",
    "        for i, response in enumerate(responses)\n",
    "    ])\n",
    "\n",
    "    chatml = [\n",
    "        situation(instruction),\n",
    "        thought(f\"Thoughts:\\n\\n{thoughts_text}\"),\n",
    "        me(answer),\n",
    "    ]\n",
    "\n",
    "    return dict(chatml=chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac0d8238-a9c8-4752-b323-e0e33724cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = np.array([t for t in orca_mini_prompt_response[\"train\"][\"token_count\"] if t < 2048])\n",
    "# plt.hist(lens, 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3014f7a8-7e72-4219-811d-5936a3fa0fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final = filtered_dataset.map(to_chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d5605df-a88e-4aad-acfc-e4f904977383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3122ba263dce40b2892e0e0315f159a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aa8fc4af9d4b368b6d2d68ed6fc81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e220213cf57b43399af6e4ab3fbf2d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a649199414064adba3dcb742ea5810b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ef00862856444381fa9be757e82579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cca3a2a25e14b85b96c014116dbaf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final.push_to_hub(\"diwank/prm800k-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620af98-4450-43d7-9c88-2abb846961a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
