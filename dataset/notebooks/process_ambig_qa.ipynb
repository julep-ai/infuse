{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441a6ddd-31ca-4be1-8d23-c2e4053b0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: ambig_qa/full\n",
      "Found cached dataset ambig_qa (/home/diwank/.cache/huggingface/datasets/ambig_qa/full/1.0.0/6425acf3572d4caf508123e5443753ab7ff415564753ae326ae801a0a1aa155e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87831c8a5fc3475eab3a02de8a0b2aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "dataset = load_dataset(\"ambig_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c4ae1f-2037-423d-ad9a-6c553d5848b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "def entry_to_chatml(row):\n",
    "    viewed_doc_titles = row[\"viewed_doc_titles\"]\n",
    "    nq_doc_title = row[\"nq_doc_title\"]\n",
    "    annotations = row[\"annotations\"]\n",
    "    question = row[\"question\"]\n",
    "    nq_answer = row[\"nq_answer\"]\n",
    "    [annot_type, *_] = annotations[\"type\"]\n",
    "\n",
    "    if annot_type == \"multipleQAs\":\n",
    "        [qa_pairs, *_] = annotations[\"qaPairs\"]\n",
    "        qa_pairs = list(zip(\n",
    "            qa_pairs[\"question\"],\n",
    "            map(lambda x: \", \".join(x), qa_pairs[\"answer\"]),\n",
    "        ))\n",
    "\n",
    "        lookup_result = \"\\n\\n\".join([\n",
    "            f\"Q: {q}\\nA: {a}\" for q, a in qa_pairs\n",
    "        ])\n",
    "\n",
    "    elif annot_type == \"singleAnswer\":\n",
    "        [lookup_answer, *_] = annotations[\"answer\"]\n",
    "        lookup_answer = \", \".join(lookup_answer)\n",
    "        lookup_result = f\"Source: {nq_doc_title}\\nQ: {question}\\nA: {lookup_answer}\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Not supported annot_type: {annot_type}\")\n",
    "\n",
    "    # Start preparing chatml\n",
    "    situation_content = (\n",
    "        \"User is talking to an AI Large Language Model and asking it general knowledge question.\"\n",
    "        \" The AI must not use prior knowledge or any piece of information not explicitly retrieved from reliable sources.\"\n",
    "        \" In order to ensure that the answer is based on factual, up-to-date information, the AI must make a query to `Lookup` tool for fetching relevant information before answering.\"\n",
    "    )\n",
    "\n",
    "    lookup_query = '\"' + '\", \"'.join(viewed_doc_titles) + '\"'\n",
    "    lookup_query += f', \"{question}\"'\n",
    "    thought_content = (\n",
    "        f'In order to answer this question, I need more information about \"{nq_doc_title}\".'\n",
    "        f\"\\nUse Tool: Lookup({lookup_query})\"\n",
    "    )\n",
    "\n",
    "    information_content = (\n",
    "        f\"Lookup Result:\\n\\n{lookup_result}\"\n",
    "    )\n",
    "    \n",
    "    chatml = [\n",
    "        situation(situation_content),\n",
    "        person(question),\n",
    "        thought(thought_content),\n",
    "        information(information_content),\n",
    "        me(name=\"AI\", content=f\"The correct answer is: {', '.join(nq_answer)}\"),\n",
    "    ]\n",
    "\n",
    "    return dict(chatml=chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff31fb1-de86-4745-847c-6ab0d4c5a29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(entry_to_chatml).remove_columns(['id', 'question', 'annotations', 'viewed_doc_titles', 'used_queries', 'nq_answer', 'nq_doc_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac455a46-847d-4c5b-b429-d968b325d0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'User is talking to an AI Large Language Model and asking it general knowledge question. The AI must not use prior knowledge or any piece of information not explicitly retrieved from reliable sources. In order to ensure that the answer is based on factual, up-to-date information, the AI must make a query to `Lookup` tool for fetching relevant information before answering.',\n",
       "  'name': 'situation',\n",
       "  'role': 'system'},\n",
       " {'content': 'When did the simpsons first air on television?',\n",
       "  'name': None,\n",
       "  'role': 'user'},\n",
       " {'content': 'In order to answer this question, I need more information about \"The Simpsons\".\\nUse Tool: Lookup(\"The Simpsons\", \"When did the simpsons first air on television?\")',\n",
       "  'name': 'thought',\n",
       "  'role': 'system'},\n",
       " {'content': 'Lookup Result:\\n\\nQ: When did the Simpsons first air on television as an animated short on the Tracey Ullman Show?\\nA: April 19, 1987\\n\\nQ: When did the Simpsons first air as a half-hour prime time show?\\nA: December 17, 1989',\n",
       "  'name': 'information',\n",
       "  'role': 'system'},\n",
       " {'content': 'The correct answer is: December 17 , 1989',\n",
       "  'name': 'AI',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['chatml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce257bbc-3687-4b9a-a28b-9a89767dc7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(transform_to_samantha_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdb5849-32a8-447e-8cee-8df0be751cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55d0a78c8a04f1b9f1edffc82f36e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd9b664df694bd4b943d41ffee2a36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403c97384cea4ee2ab86bbdc15a912fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55cabb6d4394af28d8c5c21eb53c7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b9d7b6175a40039d83939e00d5d34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ece2b9d4444f4faeb568169328fa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/ambig_qa-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4835de-b935-4349-b476-25d619323052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
