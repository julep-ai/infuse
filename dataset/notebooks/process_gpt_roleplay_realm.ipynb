{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441a6ddd-31ca-4be1-8d23-c2e4053b0425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdce6b6cc83a4a77b4aaccaa2e3d0575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/diwank/.cache/huggingface/datasets/IlyaGusev___parquet/IlyaGusev--gpt_roleplay_realm-09690c3599720f71/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6764aa4ff4e047678ddebbc7aa840073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1d0bf578694c158ba9be2d8652e17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2db5ec58f284f6594a31f68d2eba57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/202M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce82fd0d1c544d292bf29e3b6adbcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en split:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating ru split:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/diwank/.cache/huggingface/datasets/IlyaGusev___parquet/IlyaGusev--gpt_roleplay_realm-09690c3599720f71/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f031102d5f0f42918b52c92684267973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "gpt_roleplay = load_dataset(\"IlyaGusev/gpt_roleplay_realm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c4ae1f-2037-423d-ad9a-6c553d5848b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_roleplay_en = gpt_roleplay[\"en\"]\n",
    "\n",
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "def entry_to_chatml(\n",
    "    name,\n",
    "    context,\n",
    "    greeting,\n",
    "    dialog,\n",
    "    topic=None,\n",
    "):\n",
    "    # Prepare situation context\n",
    "    situation_context = f\"{context} {name} is talking to a person.\"\n",
    "    if topic:\n",
    "        situation_context += f'{name} and the person are talking about the following topic: \"{topic}\"'\n",
    "\n",
    "    # Prepare chatml\n",
    "    chatml = [\n",
    "        situation(situation_context),\n",
    "        me(name=name, content=greeting),\n",
    "    ]\n",
    "\n",
    "    for message in dialog:\n",
    "        if message[\"role\"] == \"char\":\n",
    "            chatml.append(me(\n",
    "                name=name,\n",
    "                content=message[\"content\"],\n",
    "            ))\n",
    "\n",
    "        else:\n",
    "            chatml.append(person(content=message[\"content\"]))\n",
    "\n",
    "    return chatml\n",
    "\n",
    "# example_conv_chatml = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7a06af-3011-4b5c-a879-a107469b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chatml_batch(batch):\n",
    "    # vars with x_ suffix are batches\n",
    "    # Outputs\n",
    "    chatml_ = []\n",
    "\n",
    "    # All batched inputs\n",
    "    name_ = batch[\"name\"]\n",
    "    context_ = batch[\"context\"]\n",
    "    greeting_ = batch[\"greeting\"]\n",
    "    example_dialogue_ = batch[\"example_dialogue\"]\n",
    "    topics_ = batch[\"topics\"]\n",
    "    dialogues_ = batch[\"dialogues\"]\n",
    "\n",
    "    # Add examples\n",
    "    for i, example_dialogue in enumerate(example_dialogue_):\n",
    "        k = entry_to_chatml(\n",
    "            name=name_[i],\n",
    "            context=context_[i],\n",
    "            greeting=greeting_[i],\n",
    "            dialog=example_dialogue,\n",
    "            topic=None,\n",
    "        )\n",
    "        \n",
    "        chatml_.append(k)\n",
    "\n",
    "    # Add the rest\n",
    "    for i, dialogues in enumerate(dialogues_):    \n",
    "        for dialog in dialogues:\n",
    "            k = entry_to_chatml(\n",
    "                name=name_[i],\n",
    "                context=context_[i],\n",
    "                greeting=greeting_[i],\n",
    "                dialog=dialog[\"chat\"],\n",
    "                topic=topics_[i],\n",
    "            )\n",
    "            \n",
    "            chatml_.append(k)\n",
    "\n",
    "    none_seq = [None] * len(chatml_)\n",
    "    return dict(\n",
    "        chatml=chatml_,\n",
    "        name=none_seq,\n",
    "        context=none_seq,\n",
    "        greeting=none_seq,\n",
    "        example_dialogue=none_seq,\n",
    "        topics=none_seq,\n",
    "        dialogues=none_seq,\n",
    "        image=none_seq,\n",
    "        image_prompt=none_seq,\n",
    "        char_id=none_seq,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9eb658e-382a-40e4-99d4-517506ef457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/IlyaGusev___parquet/IlyaGusev--gpt_roleplay_realm-09690c3599720f71/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-fd1b1ef35a94d43e.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = gpt_roleplay_en.map(\n",
    "    map_chatml_batch,\n",
    "    batched=True,\n",
    ").remove_columns([\n",
    "    \"name\",\n",
    "    \"context\",\n",
    "    \"greeting\",\n",
    "    \"example_dialogue\",\n",
    "    \"topics\",\n",
    "    \"dialogues\",\n",
    "    \"image\",\n",
    "    \"image_prompt\",\n",
    "    \"char_id\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce257bbc-3687-4b9a-a28b-9a89767dc7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/IlyaGusev___parquet/IlyaGusev--gpt_roleplay_realm-09690c3599720f71/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e2484afd9af5b7d9.arrow\n"
     ]
    }
   ],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(transform_to_samantha_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bdb5849-32a8-447e-8cee-8df0be751cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5093a909230d41a18b49bd0336a802fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a056af042ca4885847ae7c6a1e9d133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1f92f29c5e4772b758c70c0f73cc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/gpt_roleplay_realm-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4835de-b935-4349-b476-25d619323052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
