{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441a6ddd-31ca-4be1-8d23-c2e4053b0425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708df3af5be64cff84ac45085c8f8046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0174037ea5054823bec1363405a7b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c475d581841488c8f63c90e6256d167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251bd80f030d4ae1becde293c8710043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/202M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f989d41ad1154dbab6bc02760b4baa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ae3c0c3edb430797649d666b00155a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating en split:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4d10c20851428f932b49c03ea3b7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating ru split:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "gpt_roleplay = load_dataset(\"IlyaGusev/gpt_roleplay_realm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c4ae1f-2037-423d-ad9a-6c553d5848b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_roleplay_en = gpt_roleplay[\"en\"]\n",
    "\n",
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683c0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entry_to_chatml(\n",
    "    name,\n",
    "    context,\n",
    "    greeting,\n",
    "    dialog,\n",
    "    topic=None,\n",
    "):\n",
    "    # Prepare situation context\n",
    "    situation_context = f\"{context} {name} is talking to a person.\"\n",
    "    if topic:\n",
    "        if type(topic) == list:\n",
    "            topic = \"\\n- \".join(topic)\n",
    "\n",
    "        situation_context += f'{name} and the person are talking about:\\n- {topic}'\n",
    "\n",
    "    # Prepare chatml\n",
    "    chatml = [\n",
    "        situation(situation_context),\n",
    "        me(name=name, content=greeting),\n",
    "    ]\n",
    "\n",
    "    for message in dialog:\n",
    "        if message[\"role\"] == \"char\":\n",
    "            chatml.append(me(\n",
    "                name=name,\n",
    "                content=message[\"content\"],\n",
    "            ))\n",
    "\n",
    "        else:\n",
    "            chatml.append(person(content=message[\"content\"]))\n",
    "\n",
    "    return chatml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7a06af-3011-4b5c-a879-a107469b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chatml_batch(batch):\n",
    "    # vars with x_ suffix are batches\n",
    "    # Outputs\n",
    "    chatml_ = []\n",
    "\n",
    "    # All batched inputs\n",
    "    name_ = batch[\"name\"]\n",
    "    context_ = batch[\"context\"]\n",
    "    greeting_ = batch[\"greeting\"]\n",
    "    example_dialogue_ = batch[\"example_dialogue\"]\n",
    "    topics_ = batch[\"topics\"]\n",
    "    dialogues_ = batch[\"dialogues\"]\n",
    "\n",
    "    # Add examples\n",
    "    for i, example_dialogue in enumerate(example_dialogue_):\n",
    "        k = entry_to_chatml(\n",
    "            name=name_[i],\n",
    "            context=context_[i],\n",
    "            greeting=greeting_[i],\n",
    "            dialog=example_dialogue,\n",
    "            topic=None,\n",
    "        )\n",
    "        \n",
    "        chatml_.append(k)\n",
    "\n",
    "    # Add the rest\n",
    "    for i, dialogues in enumerate(dialogues_):    \n",
    "        for dialog in dialogues:\n",
    "            k = entry_to_chatml(\n",
    "                name=name_[i],\n",
    "                context=context_[i],\n",
    "                greeting=greeting_[i],\n",
    "                dialog=dialog[\"chat\"],\n",
    "                topic=topics_[i],\n",
    "            )\n",
    "            \n",
    "            chatml_.append(k)\n",
    "\n",
    "    none_seq = [None] * len(chatml_)\n",
    "    return dict(\n",
    "        chatml=chatml_,\n",
    "        name=none_seq,\n",
    "        context=none_seq,\n",
    "        greeting=none_seq,\n",
    "        example_dialogue=none_seq,\n",
    "        topics=none_seq,\n",
    "        dialogues=none_seq,\n",
    "        image=none_seq,\n",
    "        image_prompt=none_seq,\n",
    "        char_id=none_seq,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9eb658e-382a-40e4-99d4-517506ef457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea08f03a6bef4dc5b917c8c7a883d86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = gpt_roleplay_en.map(\n",
    "    map_chatml_batch,\n",
    "    batched=True,\n",
    ").remove_columns([\n",
    "    \"name\",\n",
    "    \"context\",\n",
    "    \"greeting\",\n",
    "    \"example_dialogue\",\n",
    "    \"topics\",\n",
    "    \"dialogues\",\n",
    "    \"image\",\n",
    "    \"image_prompt\",\n",
    "    \"char_id\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce257bbc-3687-4b9a-a28b-9a89767dc7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d707bb688241a5800605efd8c37a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(transform_to_samantha_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdb5849-32a8-447e-8cee-8df0be751cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194272d5a1f54099aca0a712a7c4ba96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3132d0c67c1548db8ac0e090b533e02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a894e43467d43b6a9d3559fdd30849c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e1b8a288284c1caaab035341d0e224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/gpt_roleplay_realm-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4835de-b935-4349-b476-25d619323052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
