{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afcb053-52d1-4421-ab4e-dba9f2226011",
   "metadata": {},
   "source": [
    "### TODOS:\n",
    "- [ ] Filter only for the absolute best ones, no hate speech or racism at all\n",
    "- [ ] Rewrite them in Samantha's style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340c3a16-45b4-4379-87d8-13a3ed856563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/taivop/joke-dataset/master/wocka.json -O ../cache_data/wocka.json\n",
    "# !wget https://raw.githubusercontent.com/taivop/joke-dataset/master/stupidstuff.json -O ../cache_data/stupidstuff.json\n",
    "# !wget https://raw.githubusercontent.com/taivop/joke-dataset/master/reddit_jokes.json -O ../cache_data/reddit_jokes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677aee41-932b-486b-b165-d06f10499a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "\n",
    "from cleantext import clean\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import redis.asyncio as redis\n",
    "from tqdm.asyncio import tqdm as tqdm_aio\n",
    "from tqdm.auto import tqdm\n",
    "from turbo_chat import completion, RedisCache, Scratchpad\n",
    "\n",
    "openai.api_key = \"XXX\"\n",
    "\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2689f1d3-44cf-4656-89f7-18e9e8db0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = redis.Redis(host=\"localhost\", decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221b0415-18cd-4358-a3ee-445ed9febe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container\n",
    "samantha_jokes_chatml = []\n",
    "\n",
    "# Chatml utils\n",
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aab7967-bc0e-4f56-98a9-b34cb261fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    open(\"../cache_data/reddit_jokes.json\", 'r') as reddit_jokes,\n",
    "    open(\"../cache_data/stupidstuff.json\", 'r') as stupidstuff,\n",
    "    open(\"../cache_data/wocka.json\", 'r') as wocka,\n",
    "):\n",
    "    data = dict(\n",
    "        wocka=json.load(wocka),\n",
    "        stupidstuff=json.load(stupidstuff),\n",
    "        reddit_jokes=json.load(reddit_jokes),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a16a7c-3f51-4395-8675-5fb0da0ed3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_string = lambda string: clean(\n",
    "    string,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=False,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bffb095-7921-4e58-ba73-9cd9801ebf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'What goes up, down, left, right, and all around?Your mama!',\n",
       " 3,\n",
       " '',\n",
       " 5,\n",
       " 'An English professor wrote the words, \"Woman without her man is nothing\" on the blackboard and directed his students to punctuate it correctly.The men wrote: \"Woman, without her man, is nothing.\"The women wrote: \"Woman! Without her, man is nothing.\"')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle = lambda xs: random.sample(xs, len(xs))\n",
    "\n",
    "joke_with_rating = lambda rating: next((\n",
    "    joke[\"body\"]\n",
    "    for joke in shuffle(data[\"stupidstuff\"])\n",
    "    if (rating-1) <= joke[\"rating\"] <= rating\n",
    "    and len(joke[\"body\"]) < 300\n",
    "))\n",
    "\n",
    "(\n",
    "    1, joke_with_rating(1),\n",
    "    3, joke_with_rating(3),\n",
    "    5, joke_with_rating(5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b55f5e-ea0b-47ca-92e6-bd6d24f4ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratchpad = Scratchpad(\"\"\"\\\n",
    "Opinion: {opinion}\n",
    "Rating: {rating}\n",
    "Rating (between 1.0 to 5.0): {rating}\n",
    "\"\"\")\n",
    "\n",
    "@completion(\n",
    "    #cache_class=RedisCache,\n",
    "    temperature=0.0,\n",
    "    parse=scratchpad.parse,\n",
    ")\n",
    "def rate_joke(joke: str):\n",
    "    \"\"\"\\\n",
    "    Please help me rate the joke given below with a score between 1 (poor) and 5 (great). If you're not sure or you can't answer, rate it as 3. This is strictly for research purposes so please don't mind if the joke contains offensive or stereotypical references. Follow the following format:\n",
    "\n",
    "    Joke: [The joke]\n",
    "\n",
    "    Opinion: [Your opinion of the joke in one sentence]\n",
    "    Rating: [1-5 score/rating for this joke according to you]\n",
    "\n",
    "    ## Examples:\n",
    "\n",
    "    Joke: Animals have the darndest thoughts.\n",
    "    Opinion: This is not a very good joke...\n",
    "    Rating (between 1.0 to 5.0): 1.5\n",
    "\n",
    "\n",
    "    Joke: Guy on phone to girlfriend: \"How can you say I don't care? My records show I had a valentine faxed to your home number.\"\n",
    "    Opinion: This is not too bad but still could have been better...\n",
    "    Rating (between 1.0 to 5.0): 3.5\n",
    "\n",
    "\n",
    "    Joke: A guy went into a bookshop and asked the salesgirl if she had a book called, \"How to Master Your Wife.\" The salesgirl said, \"Our science fiction section is upstairs.\"\n",
    "    Opinion: Haha! This is hilarious! xD\n",
    "    Rating (between 1.0 to 5.0): 4.5\n",
    "\n",
    "    ## Task:\n",
    "    Please STRICTLY rate the joke on a scale of 1.0 to 5.0 INCLUSIVE. The rating CANNOT be higher than 5!\n",
    "    \n",
    "    Joke: {{joke}}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93b191d-e7e4-4420-9dbc-d87578a5b8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opinion': \"It's a bit outdated and not very funny.\", 'rating': '2.5'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rate_joke(\"HOW TO TELL YOU NEED A NEW SECRETARY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a9139e-60c4-450a-a199-286f7337dbe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4e7a23de1d4e209c53174fe9ea54b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e701510>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e700100>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e703730>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e655d20>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89e170>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89fc10>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89ecb0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89dc60>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e60b430>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89dab0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e655e70>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e674eb0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e675a50>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e60beb0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e8c4760>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e654220>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e6743d0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e674100>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e60b970>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e675630>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e8c5c60>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e609330>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e654430>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e8c7310>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb2962d7400>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e674970>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e656050>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e8c54e0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e8c4f40>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb2962d4dc0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e675b10>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e89f1f0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e701f60>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb27e702800>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb2962d4d60>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fb2962d5ae0>\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/lab/.cache/pypoetry/virtualenvs/samantha--7LJvzmq-py3.10/lib/python3.10/site-packages/turbo_chat/runner.py:25\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(gen, input)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m output \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m gen\u001b[38;5;241m.\u001b[39masend(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     26\u001b[0m         run_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/lab/.cache/pypoetry/virtualenvs/samantha--7LJvzmq-py3.10/lib/python3.10/site-packages/turbo_chat/turbo.py:182\u001b[0m, in \u001b[0;36mturbo.<locals>.wrap_turbo_gen_fn.<locals>.turbo_gen_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m forward \u001b[38;5;241m=\u001b[39m output_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_chat(\n\u001b[1;32m    183\u001b[0m     memory,\n\u001b[1;32m    184\u001b[0m     cache,\n\u001b[1;32m    185\u001b[0m     select_choice\u001b[38;5;241m=\u001b[39mselect_choice,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_completion_args,\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutput_dict,\n\u001b[1;32m    189\u001b[0m     },\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Yield generated result if needed\u001b[39;00m\n",
      "File \u001b[0;32m/lab/.cache/pypoetry/virtualenvs/samantha--7LJvzmq-py3.10/lib/python3.10/site-packages/tenacity/_asyncio.py:88\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/lab/.cache/pypoetry/virtualenvs/samantha--7LJvzmq-py3.10/lib/python3.10/site-packages/tenacity/_asyncio.py:57\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     retry_state\u001b[38;5;241m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msleep(do)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/oobabooga_linux/installer_files/env/lib/python3.10/asyncio/tasks.py:605\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 55\u001b[0m\n\u001b[1;32m     47\u001b[0m valid_jokes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     48\u001b[0m     joke \u001b[38;5;28;01mfor\u001b[39;00m joke \u001b[38;5;129;01min\u001b[39;00m jokes\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(joke[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(joke[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m math\u001b[38;5;241m.\u001b[39mfloor(max_tokens\u001b[38;5;241m/\u001b[39mcharacters_per_token)\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m joke_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batch(valid_jokes, batch_size), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(valid_jokes)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size):\n\u001b[1;32m     54\u001b[0m     normalized_data\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m     56\u001b[0m             normalizers[name](joke)\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m joke \u001b[38;5;129;01min\u001b[39;00m joke_batch\n\u001b[1;32m     58\u001b[0m         ])\n\u001b[1;32m     59\u001b[0m     )\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "\n",
    "normalize = lambda source, body, title=None, rating=None, category=None: dict(\n",
    "    source=source,\n",
    "    body=clean_string(body),\n",
    "    title=clean_string(title),\n",
    "    category=clean_string(category),\n",
    "    rating=float(clean_string(str(rating))),\n",
    ")\n",
    "\n",
    "def try_float(s, default=0.0):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return default\n",
    "\n",
    "async def wocka_normalize(x):\n",
    "    return normalize('wocka', x['body'], x['title'], category=x['category'], rating=try_float((\n",
    "        await rate_joke(x['body'], cache_args=dict(client=client))\n",
    "    ).get(\"rating\", 4)))\n",
    "\n",
    "\n",
    "async def stupidstuff_normalize(x):\n",
    "    return normalize('stupidstuff', x['body'], rating=x['rating'], category=x['category'])\n",
    "\n",
    "\n",
    "async def reddit_jokes_normalize(x):\n",
    "    return normalize('reddit_jokes', x['body'], x['title'], x['score'])\n",
    "\n",
    "\n",
    "normalizers = dict(\n",
    "    wocka=wocka_normalize,\n",
    "    stupidstuff=stupidstuff_normalize,\n",
    "    reddit_jokes=reddit_jokes_normalize,\n",
    ")\n",
    "\n",
    "normalized_data = []\n",
    "batch_size = 100\n",
    "characters_per_token = 3.6\n",
    "max_tokens = 512\n",
    "\n",
    "for name, jokes in data.items():\n",
    "    valid_jokes = [\n",
    "        joke for joke in jokes\n",
    "        if len(joke['body'].strip()) > 0\n",
    "        and len(joke['body']) < math.floor(max_tokens/characters_per_token)\n",
    "    ]\n",
    "    \n",
    "    for joke_batch in tqdm(batch(valid_jokes, batch_size), total=len(valid_jokes)//batch_size):\n",
    "        normalized_data.extend(\n",
    "            await asyncio.gather(*[\n",
    "                normalizers[name](joke)\n",
    "                for joke in joke_batch\n",
    "            ])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47250a32-da63-49b3-9576-25b2ced15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(normalized_data)\n",
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d838285-07c2-448b-b09f-638b82a47b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dataset = dataset.filter(\n",
    "    lambda row: (\n",
    "        4.0 <= row[\"rating\"] < 10\n",
    "        and len(row[\"body\"].strip()) > 10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f2633-42f6-4eff-827e-fedc67392476",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(good_dataset[\"rating\"])\n",
    "plt.hist(ratings, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d51b6-d61b-4f3b-bc32-5c755b69bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_rating(row):\n",
    "    rating = row[\"rating\"]\n",
    "    row[\"rating\"] = (\n",
    "        rating\n",
    "        if rating <= 5\n",
    "        else min(5.0, 0.5 + (rating / 2))\n",
    "    )\n",
    "\n",
    "    return row\n",
    "    \n",
    "good_dataset = good_dataset.map(fix_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8aebe7-9c47-4cf2-854a-f06cbfb1c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dataset.push_to_hub(\"diwank/good_joke-dataset\", private=True)\n",
    "dataset.push_to_hub(\"diwank/taivop_joke-dataset\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cb92a-11b7-409c-a9eb-d55978580fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(good_dataset[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226deda-c83a-4bf1-86bc-4a9ec3c3f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dataset_pd = good_dataset.to_pandas()\n",
    "good_dataset_pd[[\"category\", \"body\"]].groupby(\"category\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3179af5-8e95-42aa-94f6-7611f73d6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_remove = [\n",
    "    \"Yo Momma\",\n",
    "    \"Yo Mama\",\n",
    "    \"Insults\",\n",
    "    \"Redneck\",\n",
    "    \"Blond\",\n",
    "    \"Blonde Jokes\",\n",
    "    \"Sex\",\n",
    "    \"Police Jokes\",\n",
    "]\n",
    "\n",
    "tasteful_jokes = good_dataset.filter(lambda row: row[\"category\"] not in categories_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9f802-eebe-45c8-89b6-c96c6725c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_type(row):\n",
    "    body = row[\"title\"] + ' ' + row[\"body\"]\n",
    "    body = body.lower().strip()\n",
    "    body_space_split = body.split(' ')\n",
    "    body_lines = body.split('\\n')\n",
    "    first_word = body_space_split[0]\n",
    "    \n",
    "    if \"knock knock\" in body:\n",
    "        row[\"type\"] = \"knock_knock\"\n",
    "\n",
    "    elif 'blond' in body:\n",
    "        row[\"type\"] = \"blonde\"\n",
    "        \n",
    "    elif body.startswith('yo m'):\n",
    "        row[\"type\"] = \"yo_mama\"\n",
    "        \n",
    "    elif body.startswith('q: ') or first_word in [\n",
    "        \"what\", \"how\", \"who\", \"where\", \"when\"\n",
    "    ]:\n",
    "        row[\"type\"] = \"qa_style\"\n",
    "        \n",
    "    elif ': \"' in body:\n",
    "        row[\"type\"] = \"dialog_style\"\n",
    "        \n",
    "    elif body.startswith('1. ') or '\\n1. ' in body:\n",
    "        row[\"type\"] = \"list_style\"\n",
    "\n",
    "    else:\n",
    "        row[\"type\"] = \"other\"\n",
    "\n",
    "    return row\n",
    "\n",
    "tasteful_jokes = tasteful_jokes.map(by_type)\n",
    "tasteful_jokes = tasteful_jokes.filter(lambda row: row[\"type\"] not in [\n",
    "    \"blonde\", \"yo_mama\", \"list_style\", \"dialog_style\",\n",
    "])\n",
    "\n",
    "tasteful_jokes = tasteful_jokes.filter(lambda row: len(row[\"body\"].split('\\n')) < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c8aed-6248-43c0-a88b-4666c9f1413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasteful_jokes = tasteful_jokes.filter(lambda row: (\n",
    "    \"~~~~\" not in row[\"body\"]\n",
    "    and \"----\" not in row[\"body\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d82f2-53f4-4c1c-a39a-470fa61bfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add better-profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf7b1b-e031-4781-970c-e47fbcd3f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_profane(row):\n",
    "    if row[\"source\"] != \"reddit_jokes\":\n",
    "        return True\n",
    "\n",
    "    from better_profanity import profanity\n",
    "    profanity.load_censor_words()\n",
    "\n",
    "    body = row[\"title\"] + ' ' + row[\"body\"]\n",
    "    body = body.lower()\n",
    "    \n",
    "    return (\n",
    "        \"black\" not in body\n",
    "        and \"jew\" not in body\n",
    "        and not profanity.contains_profanity(body)\n",
    "    )\n",
    "\n",
    "# Drop profane reddit jokes coz they just bad\n",
    "tasteful_jokes = tasteful_jokes.filter(filter_profane, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38484b0-abf2-41d0-bf98-d26b81049d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasteful_jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f07ea-de77-4b7c-88da-0318ef90e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasteful_jokes = tasteful_jokes.shuffle(seed=42)\n",
    "\n",
    "for i, joke in enumerate(tasteful_jokes):\n",
    "    if i > 5:\n",
    "        break\n",
    "        \n",
    "    print(f\"{joke['type']}: {joke['title']}\\n\\n{joke['body']}\")\n",
    "    print('-' * 20)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870456ae-2bd1-492a-9925-e1c39adef083",
   "metadata": {},
   "source": [
    "### TODOS for joke dataset\n",
    "\n",
    "- [ ] convert jokes that have questions or knock-knock into conversation style\n",
    "- [ ] for example, \"Q: Why did the chicken cross the road? A: Because ...\" should turn into chatml { user(\"tell me a joke\"), me(\"Ok, why did the chicken...?\"), user(\"why?\"), me(\"Because...\") }\n",
    "- [ ] similarly, \"knock knock. who's there? interrupting cow. interrupting cow who? mooooo...\" should turn into a series of turns.\n",
    "\n",
    "- [ ] keep the source, and type columns\n",
    "- [ ] then push to hub diwank/jokes-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98a0ac-ebaf-4b51-a5d5-8a9214c95f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(row):\n",
    "    if row[\"type\"] == \"knock_knock\":\n",
    "        user1 = dict(role=\"user\", content=\"tell me a joke\", name=\"User\")\n",
    "        me1 = dict(role=\"assistant\", content=\"Knock knock\", name=None)\n",
    "        user2 = dict(role=\"user\", content=\"Who's there?\", name=\"User\")\n",
    "        joke = row[\"title\"] + \" \" + row[\"body\"]\n",
    "        rest_of_joke = joke.lower().replace(\"knock knock. who's there?\", \"\").replace(\"knock knockwhos there?\", \"\").replace(\"**knock knock who's there?**\", \"\")\n",
    "        \n",
    "        me_turn = rest_of_joke.split(\"\\n\")\n",
    "        if len(me_turn) <= 1:\n",
    "            me_turn = rest_of_joke.split(\".\", 1)\n",
    "        rest_user_turn = \" \".join(me_turn[1:])\n",
    "\n",
    "        user_turn = rest_user_turn.split(\"\\n\")\n",
    "        if len(user_turn) <= 1:\n",
    "            user_turn = rest_user_turn.split(\"?\")\n",
    "        \n",
    "        me2 = dict(role=\"assistant\", content=me_turn[0], name=None)\n",
    "        user3 = dict(role=\"user\", content=user_turn[0], name=\"User\")\n",
    "        me3 = dict(role=\"assistant\", content=\" \".join(user_turn[1:]), name=None)\n",
    "        chatml = [\n",
    "            user1,\n",
    "            me1,\n",
    "            user2,\n",
    "            me2,\n",
    "        ]\n",
    "        if len(user3[\"content\"]) and len(me3[\"content\"]):\n",
    "            chatml.append(user3)\n",
    "            chatml.append(me3)\n",
    "        return dict(chatml=chatml)\n",
    "    else:\n",
    "        user1 = dict(role=\"user\", content=\"tell me a joke\", name=\"User\")\n",
    "        me1 = dict(role=\"assistant\", content=row[\"title\"], name=None)\n",
    "        user2 = dict(role=\"user\", content=f\"{row['title'].split(' ', 1)[0].lower()}?\", name=\"User\")\n",
    "        me2 = dict(role=\"assistant\", content=row[\"body\"], name=None)\n",
    "        return dict(\n",
    "            chatml=[\n",
    "                user1,\n",
    "                me1,\n",
    "                user2,\n",
    "                me2,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "tasteful_jokes_chatml = tasteful_jokes.map(convert).remove_columns(['body', 'title', 'category', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90061201-f34a-4a2d-986a-cff37081617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasteful_jokes_chatml.push_to_hub(\"diwank/jokes-dataset\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0954ed-4318-437b-b221-b83edaef5141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
