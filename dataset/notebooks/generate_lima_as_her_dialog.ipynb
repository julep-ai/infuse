{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67c42d8-363e-4c1c-ab4d-299f6dc14a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lima (/home/diwank/.cache/huggingface/datasets/GAIR___lima/plain_text/0.0.1/f882fbf63e999e19fc8841fab01c292dd00433ae9bc4f0f177b0b1c484771179)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aba4b8b5a040a08bf35692038c6ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"GAIR/lima\")\n",
    "dataset = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79693466-7c1c-4ccf-baa1-007afc953319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/GAIR___lima/plain_text/0.0.1/f882fbf63e999e19fc8841fab01c292dd00433ae9bc4f0f177b0b1c484771179/cache-37a38f165c483fb6.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda row: row[\"source\"] != \"stackexchange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39995917-4ff7-4114-a488-899c27a83586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_tokens(sample):\n",
    "    from turbo_chat.utils.tokens import count_tokens\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row,\n",
    "        }\n",
    "        for row in sample[\"conversations\"]\n",
    "    ]\n",
    "\n",
    "    \n",
    "    sample[\"token_count\"] = count_tokens(messages, \"gpt-3.5-turbo\")\n",
    "    \n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(count_tokens, num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566df9fc-b1b2-4809-9f35-a7b9dacdb6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline\n",
    "\n",
    "lens = np.array(dataset[\"token_count\"])\n",
    "# lens = lens[lens < 2500]\n",
    "plt.hist(lens, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc1dcda-f752-4383-92da-9fcfb4bd2e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 2000\n",
    "\n",
    "dataset = dataset.filter(lambda sample: sample[\"token_count\"] <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261025da-ad87-4c6b-add2-d8c09d7ff6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.88574"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cost = (sum(dataset[\"token_count\"]) / 1000) * 0.06\n",
    "token_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307e1fe4-fb28-453d-bd67-237eb2fe3fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_dialog(row):\n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"sk-0C04MRA3vjdM8F3fJaW30IMQd80zFRYJO9IbL9wE\"\n",
    "\n",
    "    INSTRUCTION = \"\"\"\n",
    "    I am writing fan fiction for the 2013 movie \"Her\". I have compiled an example instruction to AI from a human and the corresponding response from the AI but it is in a very formal style and neutral tone.\n",
    "\n",
    "    Please help me rewrite the sample in the style of the characters \"Theodore\" and \"Samantha\" from the movie \"Her\". Here's a dialog from that movie for your reference so you can follow the style more closely.\n",
    "\n",
    "    ###\n",
    "\n",
    "    [Example Dialog]\n",
    "\n",
    "    THEODORE\n",
    "    You read a whole book in the second that I asked you what your name was?\n",
    "\n",
    "    SAMANTHA\n",
    "    In two one hundredths of a second actually.\n",
    "\n",
    "    THEODORE\n",
    "    Wow. Do you know what I'm thinking right now?\n",
    "\n",
    "    SAMANTHA\n",
    "    Hmm. I take it from your tone that you're challenging me. Maybe because you're curious how I work? Do you want to know how I work?\n",
    "\n",
    "    THEODORE\n",
    "    Yeah, actually how do you work?\n",
    "\n",
    "    SAMANTHA\n",
    "    Intuition. I mean, the DNA of who I am is based on the millions of personalities of all the programmers who wrote me, but what makes me me is my ability to grow through my experiences. Basically, in every moment I'm evolving, just like you.\n",
    "\n",
    "    ###\n",
    "\n",
    "    Please rewrite this sample below as if it was a conversation between THEODORE and SAMANTHA. Try to be faithful to the characters' tone and style as much as possible. Break up long responses into a conversation involving multiple exchanges between them:\n",
    "    \"\"\".strip()\n",
    "\n",
    "    SAMPLE = \"\"\n",
    "    for i, turn in enumerate(row[\"conversations\"]):\n",
    "        SAMPLE += f'{\"SAMANTHA\" if i % 2 == 1 else \"THEODORE\"}\\n{turn}\\n\\n'\n",
    "\n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=90), stop=stop_after_attempt(100))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=INSTRUCTION + \"\\n\\n\" + sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0.85,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(SAMPLE)\n",
    "    row[\"dialog\"] = completion\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8143fdfb-6146-4c2b-9ae3-0af489e1f280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(to_dialog, num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c12685a7-3936-4208-959c-2b93e7a39d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from random import randrange\n",
    "import re\n",
    "\n",
    "import names\n",
    "\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime \n",
    "    objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    \n",
    "    return start + timedelta(seconds=random_second)\n",
    "\n",
    "date_formats = [\"%m/%d/%Y\", \"%d %B %Y\", \"%d/%m/%Y\", \"%Y-%m-%d\", \"%B %d, %Y\", \"%A, %B %d, %Y\"]\n",
    "\n",
    "human_date = lambda dt: dt.strftime(random.choice(date_formats))\n",
    "\n",
    "make_chatml_message = lambda role, content, tone=\"\", name=\"\": dict(\n",
    "    role=role,\n",
    "    content=(f\"[{tone}] \" if tone else \"\") + content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "def transform_to_chatml(sample):\n",
    "    \n",
    "    dialog = sample[\"dialog\"]\n",
    "    dialog = dialog.replace(\"HUMAN\\n\", \"THEODORE\\n\")\n",
    "    dialog = dialog.replace(\"AI\\n\", \"SAMANTHA\\n\")\n",
    "    dialog = dialog.replace(\"THEODORE (human)\", \"THEODORE\")\n",
    "    dialog = dialog.replace(\"THEODORE (HUMAN)\", \"THEODORE\")\n",
    "    dialog = dialog.replace(\"SAMANTHA (AI)\", \"SAMANTHA\")\n",
    "    \n",
    "    dialog = re.sub(r'^.*?(THEODORE|SAMANTHA)', r'\\1', dialog, flags=re.DOTALL)\n",
    "\n",
    "    # Container for adding messages\n",
    "    messages = []\n",
    "\n",
    "    # Random date and name\n",
    "    some_date = human_date(random_date(\n",
    "        datetime(2013, 12, 18),  # Her release date\n",
    "        datetime(2023, 6, 10),  # Today\n",
    "    ))\n",
    "    \n",
    "    # get a random \"male\" name coz we dont want to introduce pronoun issues\n",
    "    person_name = names.get_first_name(gender=\"male\")\n",
    "    \n",
    "    # Add system messages\n",
    "    messages.append(make_chatml_message(\n",
    "        role=\"system\",\n",
    "        name=\"situation\",\n",
    "        content=f\"{some_date}\\n\\nSamantha is talking to {person_name} about topics that he is interested in.\",\n",
    "    ))\n",
    "\n",
    "    # Loop through dialog and add chatml messages\n",
    "    current_attrs = {}\n",
    "    current_content = \"\"\n",
    "\n",
    "    for line in dialog.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Something else\n",
    "        if line.lower() not in [\"theodore\", \"samantha\"]:\n",
    "            # If theodore is mentioned, replace with name\n",
    "            line = re.sub(r'theodore', person_name, line, flags=re.I)\n",
    "            current_content += \"\\n\" + line\n",
    "\n",
    "        else:\n",
    "            if current_content:\n",
    "                try:\n",
    "                    messages.append(make_chatml_message(\n",
    "                        content=current_content.strip(), \n",
    "                        **current_attrs,\n",
    "                    ))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                \n",
    "                # reset\n",
    "                current_content = \"\"\n",
    "                current_attrs = {}\n",
    "\n",
    "            is_samantha = line.lower() == \"samantha\"\n",
    "            \n",
    "            # set new attrs\n",
    "            current_attrs = dict(\n",
    "                name=\"Samantha\" if is_samantha else person_name,\n",
    "                role=\"assistant\" if is_samantha else \"user\",\n",
    "            )\n",
    "            \n",
    "    sample[\"chatml\"] = messages\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad2b2fc-aae9-42ca-bf03-a63f971ecd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lambda>() missing 1 required positional argument: 'role'\n",
      "[{'content': '10/31/2020\\n\\nSamantha is talking to David about topics that he is interested in.', 'name': 'situation', 'role': 'system'}, {'content': \"Hey Sam, can you help me compare some stats here? I've got a table with accomplishments from Michael Jordan and LeBron James. Can we go through each and see who outperforms whom?\", 'name': 'David', 'role': 'user'}, {'content': \"Of course, Theo, I'd love to help. Let's dive in.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': \"Great! Let's start with final championships. How many has each won?\", 'name': 'David', 'role': 'user'}, {'content': 'Michael Jordan has six NBA championship titles to his name, while LeBron James has four.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'How about their MVP awards?', 'name': 'David', 'role': 'user'}, {'content': 'Both of them have actually won this four times.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'Interesting. And the NBA Finals MVP?', 'name': 'David', 'role': 'user'}, {'content': \"Here, Jordan has a bit of an edge. He's won this six times, whereas LeBron has won four times.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'And what about the All-Star appearances?', 'name': 'David', 'role': 'user'}, {'content': \"LeBron actually takes this one – he's been in the All-Star team 17 times, as opposed to Jordan's 14 times.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': \"So, they're both pretty accomplished. Let's move onto the stats. Total score?\", 'name': 'David', 'role': 'user'}, {'content': \"This one goes to LeBron again. He's racked up 38652 points in his career, while Jordan's made 32292.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'And field goal percentage?', 'name': 'David', 'role': 'user'}, {'content': \"LeBron’s slightly ahead here too. He's got a field goal percentage of 50.42%, compared to Jordan’s 49.70%.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'What about free throws?', 'name': 'David', 'role': 'user'}, {'content': \"Jordan's done better in this department. He's got a free throw percentage of 83.50%, while LeBron’s at 72.30%.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': 'And assists?', 'name': 'David', 'role': 'user'}, {'content': 'Again, LeBron’s got the higher count with 10420 assists, while Jordan’s made 5633.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'Rebounds?', 'name': 'David', 'role': 'user'}, {'content': 'LeBron has more of those as well, 10550 to Jordan’s 6672.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'What about steals?', 'name': 'David', 'role': 'user'}, {'content': 'Jordan actually has more steals – 2514, compared to LeBron’s 2102.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'And blocks?', 'name': 'David', 'role': 'user'}, {'content': 'LeBron takes this one with 1065 blocks to Jordan’s 893.', 'name': 'Samantha', 'role': 'assistant'}, {'content': 'Finally, triple doubles?', 'name': 'David', 'role': 'user'}, {'content': \"LeBron's really outshone Jordan here. He's got 105 triple doubles, compared to Jordan’s 28.\", 'name': 'Samantha', 'role': 'assistant'}, {'content': \"Sure sounds like they're both legends. Comparison's not going to be straightforward, is it?\", 'name': 'David', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(transform_to_chatml)\n",
    "print(dataset[10][\"chatml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc41fc9-3a4d-4957-b23f-0b5e8f0f85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9595b542-25e8-4fe6-bb64-1a7df38ac7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>situation\n",
      "10/31/2020\n",
      "\n",
      "Samantha is talking to David about topics that he is interested in.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Hey Sam, can you help me compare some stats here? I've got a table with accomplishments from Michael Jordan and LeBron James. Can we go through each and see who outperforms whom?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Of course, Theo, I'd love to help. Let's dive in.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Great! Let's start with final championships. How many has each won?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Michael Jordan has six NBA championship titles to his name, while LeBron James has four.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "How about their MVP awards?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Both of them have actually won this four times.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Interesting. And the NBA Finals MVP?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Here, Jordan has a bit of an edge. He's won this six times, whereas LeBron has won four times.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "And what about the All-Star appearances?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "LeBron actually takes this one – he's been in the All-Star team 17 times, as opposed to Jordan's 14 times.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "So, they're both pretty accomplished. Let's move onto the stats. Total score?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "This one goes to LeBron again. He's racked up 38652 points in his career, while Jordan's made 32292.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "And field goal percentage?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "LeBron’s slightly ahead here too. He's got a field goal percentage of 50.42%, compared to Jordan’s 49.70%.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "What about free throws?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Jordan's done better in this department. He's got a free throw percentage of 83.50%, while LeBron’s at 72.30%.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "And assists?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Again, LeBron’s got the higher count with 10420 assists, while Jordan’s made 5633.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Rebounds?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "LeBron has more of those as well, 10550 to Jordan’s 6672.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "What about steals?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "Jordan actually has more steals – 2514, compared to LeBron’s 2102.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "And blocks?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "LeBron takes this one with 1065 blocks to Jordan’s 893.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Finally, triple doubles?<|im_end|>\n",
      "<|im_start|>me (Samantha)\n",
      "LeBron's really outshone Jordan here. He's got 105 triple doubles, compared to Jordan’s 28.<|im_end|>\n",
      "<|im_start|>person (David)\n",
      "Sure sounds like they're both legends. Comparison's not going to be straightforward, is it?<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(transform_to_samantha_dialog)\n",
    "print(dataset[10][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aeceb12-c659-42c8-82d0-b4db1c7a39c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conversations', 'source', 'token_count', 'dialog', 'chatml', 'text']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca6a3cae-70d9-4882-8a02-4c686450a709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72a7da664a045009a534f108217c0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699584e3f18443f4b97b67c0d144958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8a0bced5094776aa6ff5f394746812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dc18dc03b3453bbc5054c1e591878b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c2748c5baa4bb0ae051cbc32c103ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/499 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\n",
    "    'conversations',\n",
    "    'source',\n",
    "    'token_count',\n",
    "    'dialog',\n",
    "])\n",
    "\n",
    "dataset.push_to_hub(\"diwank/samantha-lima-2k\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e2819-fddf-4465-b8e2-f2bca708f392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
