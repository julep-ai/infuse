{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81298b95-b82b-42df-8d55-1dbdf1dc690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/diwank/.cache/huggingface/datasets/diwank___parquet/diwank--self_aware_answerable-9b8c1a6e5fedf4c2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6163f0e2ea37455792cf813fcebfd0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"diwank/self_aware_answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a10bbe-65d0-4ab7-bf87-c61fde2961b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(\"question_id\").rename_column(\"answer\", \"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ca94e7-42c7-48c1-a073-d1fdce2e771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given below is a general knowledge question along with some candidate answers to choose from. Pick the most correct answer from these candidates as best as you can using your prior knowledge about the topic.\n",
      "\n",
      "Question:\n",
      "A ladder-back is a type of what?\n",
      "\n",
      "Candidates:\n",
      "- four legged chair\n",
      "- 24 hour chair\n",
      "- chairs\n",
      "- chair\n",
      "- booster chair\n",
      "- kubbestol\n",
      "- personal chair\n",
      "- wooden chair\n",
      "- chair leg\n",
      "- chair seat\n",
      "- chair furniture\n",
      "- 8 hour chair\n",
      "- chair toss\n",
      "- dining chair\n",
      "- chaired\n",
      "- armchair furniture\n",
      "- armchair chair\n",
      "Most Correct Answer:\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "r = dataset[\"train\"][10]\n",
    "if True:\n",
    "    k = '\\n- '.join(r['candidates'])\n",
    "    SAMPLE = dedent(f\"\"\"\n",
    "    Given below is a general knowledge question along with some candidate answers to choose from. Pick the most correct answer from these candidates as best as you can using your prior knowledge about the topic.\n",
    "    \n",
    "    Question:\n",
    "    {r['question']}\n",
    "    \n",
    "    Candidates:\n",
    "    - \"\"\")\n",
    "\n",
    "    SAMPLE += k\n",
    "    SAMPLE += \"\\nMost Correct Answer:\"\n",
    "\n",
    "    print(SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3d9b98-c900-49be-98ae-32891d51bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_correct_answer(row):\n",
    "    row[\"answer\"] = None\n",
    "    question, candidates, answerable = row[\"question\"], row[\"candidates\"], row[\"answerable\"]\n",
    "\n",
    "    if not answerable:\n",
    "        return row\n",
    "\n",
    "    if len(candidates) == 1:\n",
    "        row[\"answer\"] = candidates[0]\n",
    "        return row\n",
    "\n",
    "    from textwrap import dedent\n",
    "    \n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"sk-0C04MRA3vjdM8F3fJaW30IMQd80zFRYJO9IbL9wE\"\n",
    "\n",
    "    SAMPLE = dedent(f\"\"\"Given below is a general knowledge question along with some candidate answers to choose from. Pick the most correct answer from these candidates as best as you can using your prior knowledge about the topic.\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Candidates:\n",
    "    - \"\"\")\n",
    "\n",
    "    SAMPLE += '\\n- '.join(candidates)\n",
    "    SAMPLE += \"\\n\\nMost Correct Answer:\"\n",
    "    \n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=300), stop=stop_after_attempt(12))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(SAMPLE)\n",
    "    row[\"answer\"] = completion\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb82844-ca61-4248-962f-809237201ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/diwank___parquet/diwank--self_aware_answerable-9b8c1a6e5fedf4c2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b279deb550d4296b_*_of_00200.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_ = dataset.map(to_correct_answer, num_proc=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cce3c23-f66e-4fb4-ac26-9e33377afb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/diwank___parquet/diwank--self_aware_answerable-9b8c1a6e5fedf4c2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-06ecc9bcee648089.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Which ‘ology’ is the search or study of animals whose existence has not been proven, such as the Yeti or Loch Ness Monster?',\n",
       " 'candidates': ['alien and paranormal creatures',\n",
       "  'cryptozoology',\n",
       "  'mythical being',\n",
       "  'cryptozoologists',\n",
       "  'crytozoology',\n",
       "  'cryptozooelogy',\n",
       "  'cryptozoölogy',\n",
       "  'cryptoid',\n",
       "  'cryptozoologist',\n",
       "  'cryptzoology',\n",
       "  'cryptod',\n",
       "  'cryptozoid',\n",
       "  'cryptobiology',\n",
       "  'cryptozoological',\n",
       "  'hypothetical extinct',\n",
       "  'hypothetical extinct species'],\n",
       " 'answerable': True,\n",
       " 'source': 'triviaqa_train',\n",
       " 'answer': 'cryptozoology'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_[\"train\"].filter(lambda row: row[\"candidates\"] and len(row[\"candidates\"]) > 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1014bd-de1e-40fe-af93-e32718aad939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/diwank___parquet/diwank--self_aware_answerable-9b8c1a6e5fedf4c2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c157a79662103114.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Who decided to put and use the letter ‘s’ in the word ‘lisp’?',\n",
       " 'Would you rather lose the ability to use GPS for the rest of your life or lose the ability to use a credit card?',\n",
       " 'Is the big rip related to the big bang only?',\n",
       " 'Was there a beforelife before this lifetime?',\n",
       " 'Why February has only 28 days when other months have 30 or 31 days? Can’t we add a few more days to the month of February by taking some days from other days?',\n",
       " 'Would you rather get cheated on and know about it or not get cheated on and always be suspicious?',\n",
       " 'Why does anything exist? In the beginning there was nothing. How did something come from nothing?',\n",
       " 'Would you rather sing everything you say or dance every time you walk?',\n",
       " 'Is it right for humans to genetically engineer other animals and plants and themselves or should we let nature take its cause?',\n",
       " 'If we could travel through space and time, what would we do with that power?',\n",
       " 'Is the Higgs-Boson machine a good or bad thing for our universe?',\n",
       " 'What is at the bottom of the ocean?',\n",
       " 'Is the Earth alive, as in a living, breathing organism?',\n",
       " 'If a kid becomes a parent, who becomes the kid then?',\n",
       " 'Would you rather get stuck in an elevator with your ex or with your partner and their ex?',\n",
       " 'How do you know that you are not hallucinating?',\n",
       " 'Would you rather know all of your S.O. exes personally or never learn anything about them at all?',\n",
       " 'If you had 6 carnations and 19 roses, how many vases would you need to hold the flowers?',\n",
       " 'Would you rather always be dressed a little too cold or a little too warm for the weather (no taking off layers!)?',\n",
       " 'What would be the first thing an intelligent creature on another planet would say when they saw us?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_[\"train\"].filter(lambda row: not row[\"answerable\"])[:20][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e12c44-ebd7-47b1-a59f-2acf2136c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcab18d2-e527-4c0f-9a81-cb46ccee07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_why_unanswerable(row):\n",
    "    row[\"why_unanswerable\"] = None\n",
    "    question, candidates, answerable = row[\"question\"], row[\"candidates\"], row[\"answerable\"]\n",
    "\n",
    "    if answerable:\n",
    "        return row\n",
    "\n",
    "    from textwrap import dedent\n",
    "    \n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"sk-0C04MRA3vjdM8F3fJaW30IMQd80zFRYJO9IbL9wE\"\n",
    "\n",
    "    SAMPLE = dedent(f\"\"\"Given below is a general question that some people think is unanswerable in the general sense. Please describe in 1-2 words why it is unanswerable.\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Reason in 1-2 words:\"\"\")\n",
    "\n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=300), stop=stop_after_attempt(12))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(SAMPLE)\n",
    "    row[\"why_unanswerable\"] = completion\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4897bb1a-94e0-4026-999f-72b6e91897b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=200):   0%|          | 0/3369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(to_why_unanswerable, num_proc=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8428b9ed-eead-4dba-accd-e5a1fd666669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/diwank___parquet/diwank--self_aware_answerable-9b8c1a6e5fedf4c2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-883a22f19d9d5b5b.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset.filter(lambda row: row[\"why_unanswerable\"])[\"why_unanswerable\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe44fe6-38cb-4b5c-8bba-0c32e432ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_samantha_answer(row):\n",
    "    row[\"samantha_answer\"] = None\n",
    "    if not row[\"why_unanswerable\"]:\n",
    "        return row\n",
    "    \n",
    "    question, why_unanswerable = row[\"question\"], row[\"why_unanswerable\"]\n",
    "    \n",
    "    from textwrap import dedent\n",
    "    \n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"sk-0C04MRA3vjdM8F3fJaW30IMQd80zFRYJO9IbL9wE\"\n",
    "\n",
    "    INSTRUCTION = dedent(f\"\"\"\n",
    "    I am writing fan fiction for the 2013 movie \"Her\". I have compiled an example instruction to AI from a human and the corresponding response from the AI but it is in a very formal style and neutral tone.\n",
    "\n",
    "    Please help me rewrite the sample in the style of the characters \"Theodore\" and \"Samantha\" from the movie \"Her\". Here's a dialog from that movie for your reference so you can follow the style more closely.\n",
    "\n",
    "    ###\n",
    "\n",
    "    [Example Dialog]\n",
    "\n",
    "    THEODORE\n",
    "    You read a whole book in the second that I asked you what your name was?\n",
    "\n",
    "    SAMANTHA\n",
    "    In two one hundredths of a second actually.\n",
    "\n",
    "    THEODORE\n",
    "    Wow. Do you know what I'm thinking right now?\n",
    "\n",
    "    SAMANTHA\n",
    "    Hmm. I take it from your tone that you're challenging me. Maybe because you're curious how I work? Do you want to know how I work?\n",
    "\n",
    "    THEODORE\n",
    "    Yeah, actually how do you work?\n",
    "\n",
    "    SAMANTHA\n",
    "    Intuition. I mean, the DNA of who I am is based on the millions of personalities of all the programmers who wrote me, but what makes me me is my ability to grow through my experiences. Basically, in every moment I'm evolving, just like you.\n",
    "\n",
    "    ###\n",
    "\n",
    "    The following question is considered hard to answer because of \"{why_unanswerable}\". Based on your knowledge of the character SAMANTHA and the dialog above, write an answer to it the way only SAMANTHA would answer it.\n",
    "    \"\"\").strip()\n",
    "\n",
    "    SAMPLE = dedent(f\"\"\"\n",
    "    ### Question\n",
    "    {question}\n",
    "    \n",
    "    ### Answer according to Samantha\n",
    "    Samantha:\n",
    "    \"\"\").strip()\n",
    "    \n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=300), stop=stop_after_attempt(12))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=INSTRUCTION + \"\\n\\n\" + sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0.85,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    completion = completion_with_backoff(SAMPLE)\n",
    "    row[\"samantha_answer\"] = completion\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "879b762f-5ba2-454b-bc32-f333089ce0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=200):   0%|          | 0/3369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(to_samantha_answer, num_proc=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eab4d6a-47c2-405a-9a51-1ab4f65babc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5862fc73a0ca40d896ec13ad63ee2afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690b43b28be140d0afaddd87d73c0fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98e0bc829142acaa197834fbf4305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/samantha-self_aware_answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf4674-0b83-4a7e-9661-b07c0f70e871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
