{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe562e23-e872-428f-ae76-9050b8df78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#wget https://github.com/cascip/ChatAlpaca/raw/main/data/chatalpaca-20k.json -O ../cache_data/chatalpaca-20k.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338c280c-7a26-4e78-bcd2-6cab5fe41d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#poetry add jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f191cb-bbf4-4644-8d8b-2dfb7c1d94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/home/diwank/.cache/huggingface/datasets/generator/default-645a65a0efdf258b/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "import jsonlines as jsonl\n",
    "from datasets import Dataset\n",
    "\n",
    "fn = \"../cache_data/chatalpaca-20k.jsonl\"\n",
    "with jsonl.open(fn) as reader:\n",
    "    def from_reader():\n",
    "        for item in reader:\n",
    "            yield item\n",
    "\n",
    "    dataset = Dataset.from_generator(from_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1319030f-cb91-414e-af19-1d6ae9a0aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dialog(row):\n",
    "    from tenacity import (\n",
    "        retry,\n",
    "        stop_after_attempt,\n",
    "        wait_random_exponential,\n",
    "    )\n",
    "\n",
    "    import openai\n",
    "    openai.api_key = \"XXX\"\n",
    "\n",
    "    from redis import StrictRedis\n",
    "    from redis_cache import RedisCache\n",
    "\n",
    "    client = StrictRedis(host=\"localhost\", decode_responses=True)\n",
    "    cache = RedisCache(redis_client=client)\n",
    "\n",
    "    INSTRUCTION = \"Analyze the following conversation between a User and an AI Large Language Model and write down the topic they are discussing or the task the AI is trying to help the User with in this situation:\"\n",
    "    \n",
    "    @cache.cache()\n",
    "    @retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(100))\n",
    "    def completion_with_backoff(sample):\n",
    "\n",
    "        messages = [dict(\n",
    "            role=\"user\",\n",
    "            content=INSTRUCTION + \"\\n\\n\" + sample\n",
    "        )]\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message[\"content\"]\n",
    "        return result\n",
    "\n",
    "    sample = \"\\n\".join([\n",
    "        f\"{'User' if item['from'] == 'human' else 'AI Large Language Model'}: {item['value']}\"\n",
    "        for item in row[\"conversations\"][:4]\n",
    "    ])\n",
    "    \n",
    "    sample += \"\\n\\nSituation:\"\n",
    "    \n",
    "    completion = completion_with_backoff(sample)\n",
    "    row[\"situation\"] = completion\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7cb3321-c9ce-40dd-9dba-9808bfb8dda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=200):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(to_dialog, num_proc=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6a87ce1-6991-4185-9b92-7d50e4048b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chatml = lambda name, role, content: dict(\n",
    "    name=name, role=role, content=content,\n",
    ")\n",
    "\n",
    "system = lambda name, content: make_chatml(\n",
    "    role=\"system\",\n",
    "    name=name,\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "situation = lambda content: system(name=\"situation\", content=content)\n",
    "thought = lambda content: system(name=\"thought\", content=content)\n",
    "information = lambda content: system(name=\"information\", content=content)\n",
    "me = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "person = lambda content, name=None: make_chatml(\n",
    "    role=\"user\",\n",
    "    content=content,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0faa3a5e-e308-4359-915b-6dba574929cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/generator/default-645a65a0efdf258b/0.0.0/cache-b9315b32301d33fd.arrow\n"
     ]
    }
   ],
   "source": [
    "def map_chatml(row):\n",
    "    chatml = [\n",
    "        situation(row[\"situation\"]),\n",
    "        *[\n",
    "            me(turn[\"value\"], name=\"AI\")\n",
    "            if turn[\"from\"] != \"human\"\n",
    "            else person(turn[\"value\"])\n",
    "            \n",
    "            for turn in row[\"conversations\"]\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    return dict(chatml=chatml)\n",
    "\n",
    "dataset = dataset.map(map_chatml).remove_columns([\n",
    "    \"id\",\n",
    "    \"conversations\",\n",
    "    \"situation\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac06015-efb3-4d69-84f2-567edf14c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/diwank/.cache/huggingface/datasets/generator/default-645a65a0efdf258b/0.0.0/cache-ed8adb32a51945fa.arrow\n"
     ]
    }
   ],
   "source": [
    "assistant_me_map = {\n",
    "    \"user\": \"person\",\n",
    "    \"assistant\": \"me\",\n",
    "}\n",
    "\n",
    "def make_sections(messages: list[dict]) -> str:\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<|im_start|>\"\n",
    "\n",
    "    result = bos_token + (eos_token+'\\n'+bos_token).join([\n",
    "        (\n",
    "            f\"{message['name']}\"\n",
    "            if message['role'] == 'system' else\n",
    "            f\"{assistant_me_map[message['role']]}{' (' + message['name'] + ')' if message['name'] else ''}\"\n",
    "        )\n",
    "        + f\"\\n{message['content'].strip()}\"\n",
    "        for message in messages\n",
    "    ]) + eos_token\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def transform_to_samantha_dialog(sample):\n",
    "\n",
    "    messages = sample[\"chatml\"]\n",
    "    sample[\"text\"] = make_sections(messages)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(transform_to_samantha_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b94e728-564e-481d-a274-af2d053f822b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffbbbb3a3b245baa0a94dbefbf15981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0397b9103bb4cb78a77407931757264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d34d7fc36be4a93afdd45e2f13cf052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"diwank/chatalpaca-20k-chatml\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e4675-fe23-42b2-b506-dfc26302f7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
