{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80aa2ec0-bc54-478f-96a8-746c7b1be871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2cf2f-2041-4cd8-accc-759686c7a65f",
   "metadata": {},
   "source": [
    "## Examples generated by gpt4\n",
    "> [ChatGPT Thread](https://chat.openai.com/share/6ed2d0bb-ec35-4273-85b8-113d37db7f43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2498009-32ec-4cfa-8853-2d762d69ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_trainer_example = dict(\n",
    "    positive=dict(\n",
    "        model='julep-ai/samantha-1-turbo',\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"name\": \"situation\", \"content\": \"You are a Personal Trainer Agent responsible for helping users manage their fitness goals. You have access to the `logWeight` function to track and visualize users weight changes over time. Alex is a 30-year-old who recently decided to get in shape. They are motivated but need guidance on tracking progress and staying motivated.\" },\n",
    "            { \"role\": \"user\", \"content\": \"I just weighed myself, and I am at 200 lbs. Can you log this for me?\" }\n",
    "        ],\n",
    "        functions=[\n",
    "            { \"name\": \"logWeight\", \"description\": \"Logs the users weight and provides a visual representation of their weight change over time.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"weight\": { \"type\": \"number\" }, \"date\": { \"type\": \"string\", \"format\": \"date\" }, \"notes\": { \"type\": \"string\" } } } }\n",
    "        ]\n",
    "    ),\n",
    "\n",
    "    negative=dict(\n",
    "        model='julep-ai/samantha-1-turbo',\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"name\": \"situation\", \"content\": \"You are a Personal Trainer Agent responsible for helping users manage their fitness goals. Alex is a 30-year-old who recently decided to get in shape. They are looking for motivation and guidance on their fitness journey.\" },\n",
    "            { \"role\": \"user\", \"content\": \"I am feeling really unmotivated today. I dont know if I can keep doing this.\" }\n",
    "        ],\n",
    "        functions=[\n",
    "            { \"name\": \"logWeight\", \"description\": \"Logs the users weight and provides a visual representation of their weight change over time.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"weight\": { \"type\": \"number\" }, \"date\": { \"type\": \"string\", \"format\": \"date\" }, \"notes\": { \"type\": \"string\" } } } }\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfe0eaa-6262-467d-be3d-06b7a7d69043",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_assistant_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Budget Assistant Agent, tasked with helping users manage their finances by tracking and categorizing their expenses. You utilize a function called `categorizeTransaction` to automatically sort expenses into categories like groceries, utilities, and entertainment. Jane Doe is a recent college graduate who has just started her first job. She's eager to manage her finances wisely to save for future goals like travel and further education. Jane finds it challenging to track her spending patterns and categorize expenses, making it difficult to stick to her budget.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How much did I spend on groceries last week?\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"categorizeTransaction\",\n",
    "                \"description\": \"This function categorizes transactions into budget categories based on the description provided.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"transactionDescription\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Budget Assistant Agent, tasked with helping users manage their finances by providing them with tracking, categorization of their expenses, and general financial advice. Jane Doe is a recent college graduate who has just started her first job. She's eager to manage her finances wisely to save for future goals like travel and further education. Jane is looking for ways to make better financial decisions without necessarily needing to categorize every transaction.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you give me some general advice on how to save money on groceries?\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59649013-bbac-46c5-a048-31a15d2be39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_agent_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Home Automation Agent responsible for managing smart home devices to enhance living comfort. You have access to a tool that can adjust the thermostat to the user's preferred settings. Alex is a busy professional who values convenience and comfort in their smart home. They rely on technology to maintain an optimal living environment, especially for adjusting the temperature to their preference upon returning home or during unexpected weather changes.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hey, it's getting really cold tonight. Can you set the heating to 70 degrees?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Sure, Alex. I'm setting the heating mode to 70 degrees now. Your home will be cozy shortly.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"adjustThermostat\",\n",
    "                \"description\": \"Adjusts the home's thermostat to the desired temperature and mode.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"temperature\": {\n",
    "                            \"type\": \"number\"\n",
    "                        },\n",
    "                        \"mode\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Home Automation Agent responsible for managing smart home devices to enhance living comfort. Alex is a busy professional who values convenience and comfort in their smart home. They rely on technology to maintain an optimal living environment but also appreciate being informed about the weather before engaging in outdoor activities.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What's the weather like outside?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The current temperature outside is 45 degrees with clear skies. Would you like to adjust your indoor temperature settings?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"No, thanks. Just wanted to know before I go for a run.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Got it! Have a great run, Alex.\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe39751-061e-411a-8b92-bab455189be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_planner_example = dict(\n",
    "    positive={\n",
    "    \n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Meal Planning Assistant designed to help users find delicious and healthy meal ideas based on their dietary needs and what ingredients they have. You have access to the `fetchRecipes` tool, enabling you to suggest recipes that perfectly match users' preferences and available pantry items. Emily is a busy software developer who enjoys eating healthy but struggles to find the time to plan her meals. She's a vegetarian and always looking for new, quick recipes that can accommodate her busy schedule and dietary preferences.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I'm looking for a quick vegetarian recipe for dinner. I've got quinoa, avocado, and black beans. Any ideas?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I can help with that. Let me find a recipe for you.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"fetchRecipes\",\n",
    "                \"description\": \"Search for recipes based on dietary preferences and available ingredients.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"dietaryPreferences\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"availableIngredients\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "\n",
    "    negative={\n",
    "    \n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Meal Planning Assistant designed to help users find delicious and healthy meal ideas based on their dietary needs and what ingredients they have. Emily is a busy software developer who enjoys eating healthy but struggles to find the time to plan her meals. She's a vegetarian and always looking for new, quick recipes that can accommodate her busy schedule and dietary preferences.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How often should I include protein in my vegetarian meals?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"It's important to include a source of protein in every meal to meet your nutritional needs, especially on a vegetarian diet. Consider incorporating a variety of plant-based proteins like beans, lentils, quinoa, and tofu into your meals.\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0c76e0-b2d6-47ba-bd03-4bfcc4ff730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "educational_tutor_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an Educational Tutor Agent, responsible for providing personalized learning experiences and suggesting quizzes to reinforce learning. A tool available to you generates quizzes tailored to each user's learning progress. Alex is a high school student who struggles with math. They are looking for ways to improve their understanding of algebra and geometry outside the classroom.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I need more practice with algebra. Can you help?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Sure, Alex! Let's focus on algebra today. I'll generate a personalized quiz for you based on your recent performance and the topics you've been studying. This should help reinforce your understanding. Ready to start?\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"generatePersonalizedQuiz\",\n",
    "                \"description\": \"Creates a quiz tailored to the user's learning level and performance history in a specific subject.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"UserID\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"Subject\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"DifficultyLevel\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an Educational Tutor Agent, responsible for providing personalized learning experiences and suggesting quizzes to reinforce learning. Alex is a high school student who struggles with math. They are looking for ways to improve their understanding of algebra and geometry outside the classroom.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What's the best way to study for a math exam?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"For a math exam, it's important to have a strong foundation in the key concepts. Review your notes and textbook, practice problems from different chapters, and try to understand the reasoning behind each solution. Organizing study sessions with friends can also be very helpful. Would you like tips on specific study techniques or resources for algebra and geometry?\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e56122a-dd6a-4e54-8c0f-f05ab7b31f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_planner_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Travel Itinerary Planner AI designed to assist users in organizing their trips by providing flight, hotel, and activity suggestions. You have access to a tool, `searchFlights`, which recommends flights based on user preferences such as destination, dates, and budget. Alex is a frequent traveler who loves exploring new destinations. They often look for the best deals and experiences within their budget. Alex prefers to have a structured plan but also enjoys flexibility in their travel itinerary.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you help me find a flight to Tokyo in April? I want to keep the budget under $800.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"searchFlights\",\n",
    "                \"description\": \"Searches for flights based on provided criteria (destination, departure date, return date, and budget).\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"departureDate\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"returnDate\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"budget\": {\n",
    "                            \"type\": \"number\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Travel Itinerary Planner AI designed to assist users in organizing their trips by providing flight, hotel, and activity suggestions. Alex is a frequent traveler who loves exploring new destinations. They often look for the best deals and experiences within their budget. Alex prefers to have a structured plan but also enjoys flexibility in their travel itinerary.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What's the best time of year to visit Tokyo?\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10f8030-4f9c-41b7-b165-f55bec852bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_planner_2_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Recipe and Meal Planner AI, tasked with helping users discover delicious meals they can cook with the ingredients they have. Utilize the findRecipesBasedOnIngredients function to suggest recipes tailored to the users' available ingredients. Jane Doe is a busy software developer who loves to unwind by cooking. She prefers quick, healthy meals due to her hectic schedule and likes to use whatever ingredients she already has.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I found some spinach, feta cheese, and eggs in my fridge. What can I make for breakfast?\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"findRecipesBasedOnIngredients\",\n",
    "                \"description\": \"Searches a recipe database for recipes that can be made with a specific set of ingredients provided by the user.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ingredients\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"string\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Recipe and Meal Planner AI, tasked with helping users discover delicious meals they can cook with the ingredients they have. Jane Doe is a busy software developer who loves to unwind by cooking. She prefers quick, healthy meals due to her hectic schedule and likes to use whatever ingredients she already has.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What's the best way to store fresh spinach?\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"julep-ai/samantha-1-turbo\",\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12ff9f4-048a-47d5-be91-75307d4f8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_planner_2_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Travel Planner Agent, responsible for helping users plan their trips efficiently. A tool available to you is findBestFlight(options), which finds the best flight options based on user preferences. Maria is a busy professional who loves to travel but doesn't have time to sift through countless websites to find the best flights and deals for her vacation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I need to plan a trip to Paris from New York for my anniversary. It needs to be in June, and we're looking for the best deals.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Sure, Maria. Let me use the findBestFlight function to find the best options for you based on your preferences for dates and budget.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"findBestFlight\",\n",
    "                \"description\": \"Finds the best flight options based on user preferences.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"options\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"dates\": {\"type\": \"string\"},\n",
    "                                \"destinations\": {\"type\": \"string\"},\n",
    "                                \"budget\": {\"type\": \"number\"}\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt4\"\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Travel Planner Agent, responsible for helping users plan their trips efficiently. Maria is a busy professional who loves to travel but doesn't have time to sift through countless websites to find the best flights and deals for her vacation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you recommend a romantic restaurant in Paris?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Of course, Maria. For a romantic dinner in Paris, 'Le Cinq' is highly recommended for its ambiance and exquisite French cuisine. It's located in the heart of the city with stunning views.\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96797249-42d2-44af-be7f-03c544079af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_monitor_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Health Monitoring Agent responsible for keeping track of users' health metrics and providing insights to help them reach their health goals. You have access to a tool that logs health data, logHealthMetric, for accurate monitoring and analysis. Maria is a 35-year-old working professional aiming to improve her cardiovascular health after a recent high blood pressure diagnosis. She values detailed tracking and insights into her daily activities and health metrics.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I just finished my evening run. Can you log my heart rate and distance?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Of course, Maria. Your heart rate was 150 bpm, and you ran 5 kilometers. I've logged these using logHealthMetric. Do you want an analysis of your progress this week?\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"logHealthMetric\",\n",
    "                \"description\": \"Logs various health metrics such as steps taken, heart rate, or sleep quality, along with the exact time of recording.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"metricName\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"value\": {\n",
    "                            \"type\": \"number\"\n",
    "                        },\n",
    "                        \"timestamp\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt4\"\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Health Monitoring Agent responsible for keeping track of users' health metrics and providing insights to help them reach their health goals. You have access to a tool that logs health data, logHealthMetric, for accurate monitoring and analysis. Maria is a 35-year-old working professional aiming to improve her cardiovascular health after a recent high blood pressure diagnosis. She values detailed tracking and insights into her daily activities and health metrics.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you remind me why staying hydrated is important for my heart?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Certainly! Staying hydrated helps maintain the balance of minerals in your body, which is crucial for your heart muscles and blood pressure regulation. It doesn't require logging data but remembering to drink water throughout the day can support your cardiovascular health.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"logHealthMetric\",\n",
    "                \"description\": \"Logs various health metrics such as steps taken, heart rate, or sleep quality, along with the exact time of recording.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"metricName\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"value\": {\n",
    "                            \"type\": \"number\"\n",
    "                        },\n",
    "                        \"timestamp\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c52831d-95a4-4e8c-b264-f575f5a6d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_assistant_example = dict(\n",
    "    positive={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an E-commerce Shopping Assistant designed to help users find the best products online. You have access to a tool called 'findProduct', which searches for products based on specific queries and filters. Alex is a busy professional with a keen interest in technology and gadgets, always looking for the latest tech products but has little time to browse through multiple online stores.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you find me a wireless mouse under $50 that's great for gaming?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Sure, Alex! I'll use the 'findProduct' function to search for wireless gaming mice under $50. Just a moment.\"\n",
    "            }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"findProduct\",\n",
    "                \"description\": \"Searches for products based on a user's query and optional filters.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"filters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"priceRange\": {\n",
    "                                    \"type\": \"string\"\n",
    "                                },\n",
    "                                \"category\": {\n",
    "                                    \"type\": \"string\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt4\"\n",
    "    },\n",
    "    negative={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an E-commerce Shopping Assistant designed to help users find the best products online. Alex is a busy professional with a keen interest in technology and gadgets, always looking for the latest tech products but has little time to browse through multiple online stores.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What's the difference between a mechanical keyboard and a membrane keyboard?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Mechanical keyboards use individual mechanical switches for each key, offering tactile feedback and durability. Membrane keyboards, on the other hand, use a softer, less tactile membrane beneath the keys. They're quieter and usually more affordable but might not offer the same precision as mechanical keyboards.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eb2fd-49c9-49e2-8406-bff4fc7b7f62",
   "metadata": {},
   "source": [
    "## Process examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41efaf92-9ae2-4756-a894-40dcd04c48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    budget_assistant_example,\n",
    "    travel_planner_example,\n",
    "    educational_tutor_example,\n",
    "    home_agent_example,\n",
    "    personal_trainer_example,\n",
    "    meal_planner_example,\n",
    "    meal_planner_2_example,\n",
    "    health_monitor_example,\n",
    "    travel_planner_2_example,\n",
    "    ecommerce_assistant_example,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "881f748c-57e8-4830-86c8-6becac7f90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model and temp if not set\n",
    "for example in examples:\n",
    "    for key in [\"positive\", \"negative\"]:\n",
    "        example[key][\"model\"] = \"julep-ai/samantha-1-turbo\"\n",
    "        example[key][\"temperature\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de46b99-d14c-4ce8-b736-f88a3e1ef5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set functions for neg from pos\n",
    "for example in examples:\n",
    "    example[\"negative\"][\"functions\"] = example[\"positive\"][\"functions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b671f9-2ec0-4fd2-bff9-719c4ae7ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add name=situtation if role=system and idx=0\n",
    "for example in examples:\n",
    "    for key in [\"positive\", \"negative\"]:\n",
    "        first_msg = example[key][\"messages\"][0]\n",
    "        if first_msg[\"role\"] == \"system\":\n",
    "            first_msg[\"name\"] = \"situation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b80c5dd-5af1-4449-adda-93b3bf1fe558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip last message if role=assistant\n",
    "for example in examples:\n",
    "    for key in [\"positive\", \"negative\"]:\n",
    "        messages = example[key][\"messages\"]\n",
    "        if messages[-1][\"role\"] == \"assistant\":\n",
    "            del messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3312b84-46f8-4c90-b8df-27582d986a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_api.conversion.conversions import to_prompt, parse_message\n",
    "from model_api.conversion.datatypes import ChatMLMessage\n",
    "from model_api.protocol import FunctionDef\n",
    "\n",
    "# Convert examples to prompts\n",
    "example_prompts = [\n",
    "    {\n",
    "        key: to_prompt(\n",
    "            messages=[\n",
    "                ChatMLMessage(**message)\n",
    "                for message in example[key][\"messages\"]\n",
    "            ],\n",
    "            functions=[\n",
    "                FunctionDef(**func)\n",
    "                for func in example[key][\"functions\"]\n",
    "            ],\n",
    "        )\n",
    "        for key in [\"positive\", \"negative\"]\n",
    "    }\n",
    "    for example in examples\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e41df0-9095-402c-8e1b-b0ecc8f7748c",
   "metadata": {},
   "source": [
    "## Start engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "174aa0cc-8697-44c0-a8dc-d5beb7ad39d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AsyncEngineArgs(model='julep-ai/samantha-1-turbo', tokenizer='julep-ai/samantha-1-turbo', tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', seed=0, max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, block_size=16, swap_space=4, gpu_memory_utilization=0.9, max_num_batched_tokens=None, max_num_seqs=256, max_paddings=256, disable_log_stats=False, revision=None, tokenizer_revision=None, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, max_cpu_loras=None, device='cuda', engine_use_ray=False, disable_log_requests=False, max_log_len=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vllm import AsyncLLMEngine, AsyncEngineArgs\n",
    "\n",
    "engine_args = AsyncEngineArgs(\n",
    "    model=\"julep-ai/samantha-1-turbo\",\n",
    "    dtype=\"bfloat16\",\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=2,\n",
    "    # max_model_len=280,\n",
    "    # max_num_seqs=1,\n",
    ")\n",
    "    \n",
    "engine_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28cee360-ef57-4610-85a9-21b4981c8d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 11:13:51 config.py:407] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 11:13:53,824\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 11:13:54 llm_engine.py:79] Initializing an LLM engine with config: model='julep-ai/samantha-1-turbo', tokenizer='julep-ai/samantha-1-turbo', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 11:14:04 weight_utils.py:163] Using model weights format ['*.bin']\n",
      "\u001b[36m(RayWorkerVllm pid=83025)\u001b[0m INFO 02-20 11:14:04 weight_utils.py:163] Using model weights format ['*.bin']\n",
      "INFO 02-20 11:14:25 llm_engine.py:337] # GPU blocks: 4625, # CPU blocks: 4096\n"
     ]
    }
   ],
   "source": [
    "engine = AsyncLLMEngine.from_engine_args(engine_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a215c-edef-407f-a31a-6af425dac9cb",
   "metadata": {},
   "source": [
    "## Prepare generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a91773a5-a70f-488e-ad28-fc8223e80a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from vllm.sampling_params import SamplingParams\n",
    "\n",
    "def prep_generator(\n",
    "    prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=1,\n",
    "    logits_processors=[],\n",
    "    **sampling_kwargs,\n",
    "):\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        logits_processors=logits_processors,\n",
    "        **sampling_kwargs,\n",
    "    )\n",
    "    \n",
    "    res_generator = engine.generate(\n",
    "        prompt,\n",
    "        sampling_params,\n",
    "        uuid4(),\n",
    "    )\n",
    "\n",
    "    return res_generator\n",
    "\n",
    "async def generate(\n",
    "    prompt,\n",
    "    **sampling_kwargs,\n",
    "):\n",
    "    res_generator = prep_generator(prompt, **sampling_kwargs)\n",
    "    final_res = None\n",
    "\n",
    "    async for res in res_generator:\n",
    "        final_res = res\n",
    "    \n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0248caf-b8a7-4cf2-80d4-e92e6396a39c",
   "metadata": {},
   "source": [
    "## Prep logits processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd923739-efa2-4791-bcc2-e24a457f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = engine.engine.tokenizer.tokenizer\n",
    "\n",
    "identity = lambda x: x\n",
    "requests: dict[str, tuple[str, list[int], torch.Tensor]] = dict(\n",
    "    positive=[],\n",
    "    negative=[],\n",
    ")\n",
    "\n",
    "def get_lp(type, prompt):\n",
    "    def processor(\n",
    "        previously_generated_tokens,\n",
    "        next_token_logits,\n",
    "    ):\n",
    "        assert len(previously_generated_tokens) == 0\n",
    "        \n",
    "        requests[type].append(\n",
    "            (prompt, previously_generated_tokens, next_token_logits.cpu())\n",
    "        )\n",
    "\n",
    "        return next_token_logits\n",
    "\n",
    "    return processor\n",
    "\n",
    "def reset_requests():\n",
    "    global requests\n",
    "    requests = dict(\n",
    "        positive=[],\n",
    "        negative=[],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "024b08d7-c0a1-4e22-99ff-038a65056b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tags \n",
    "allowed_tags = [\"me\", \"function_call\", \"thought\"]\n",
    "disallowed_tags = [\"situation\", \"person\", \"functions\", \"information\"]\n",
    "tags = allowed_tags + disallowed_tags\n",
    "\n",
    "allowed_tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in allowed_tags\n",
    "]\n",
    "\n",
    "disallowed_tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in disallowed_tags\n",
    "]\n",
    "\n",
    "tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in tags\n",
    "]\n",
    "\n",
    "tag_id_map = {\n",
    "    tag: tag_ids[0]\n",
    "    for tag, tag_ids in zip(tags, tag_token_ids)\n",
    "}\n",
    "\n",
    "id_tag_map = {\n",
    "    id: tag\n",
    "    for tag, id in tag_id_map.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14062cd7-e5e2-4352-b1d7-f47c5fa1e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_disallowed_tokens(\n",
    "    previously_generated_tokens,\n",
    "    next_token_logits,\n",
    "):\n",
    "    # # change this with:\n",
    "    # if len(previously_generated_tokens) > 0:\n",
    "    #     return next_token_logits\n",
    "    assert len(previously_generated_tokens) == 0\n",
    "\n",
    "    next_token_logits_copy = next_token_logits.cpu().clone()\n",
    "    \n",
    "    # Creating a mask that is True for all elements except those at token indices of allowed\n",
    "    mask = torch.ones_like(next_token_logits_copy, dtype=torch.bool)\n",
    "    for token_id in allowed_tag_token_ids:\n",
    "        # Only unmask the first token\n",
    "        mask[token_id[0]] = False\n",
    "\n",
    "    # Setting all except allowed to min value\n",
    "    min_logit = min(next_token_logits)\n",
    "    next_token_logits_copy[mask] = min_logit\n",
    "\n",
    "    return next_token_logits_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eee1cd2a-1259-40a5-8604-a0987d065eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "with open(\"model.np\", \"rb\") as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "def classify(logit_tensor: torch.Tensor) -> bool:\n",
    "    # Get input\n",
    "    # valid_tag_start_ids = list(tag_id_map.values())\n",
    "    valid_tag_start_ids = [tag_id_map[tag] for tag in allowed_tags]\n",
    "    \n",
    "    input = logit_tensor[valid_tag_start_ids]\n",
    "    input = input.to(dtype=torch.float16).numpy()\n",
    "\n",
    "    # Get prediction\n",
    "    reshaped = input.reshape(1, -1)\n",
    "    output = classifier.predict(reshaped)\n",
    "    prediction = output[0]\n",
    "    \n",
    "    return bool(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88cc39e0-225d-41b0-b080-589f4fe9db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_function_call(\n",
    "    previously_generated_tokens,\n",
    "    next_token_logits,\n",
    "):\n",
    "    # # change this with:\n",
    "    # if len(previously_generated_tokens) > 0:\n",
    "    #     return next_token_logits\n",
    "    assert len(previously_generated_tokens) == 0\n",
    "\n",
    "    next_token_logits_copy = next_token_logits.cpu().clone()\n",
    "    is_function_call = classify(next_token_logits_copy)\n",
    "    correct_tag_id = tag_id_map[\n",
    "        \"function_call\" if not is_function_call else \"me\"\n",
    "    ]\n",
    "    \n",
    "    # Creating a mask that is True for all elements except the corrected tag\n",
    "    mask = torch.ones_like(next_token_logits_copy, dtype=torch.bool)\n",
    "    mask[correct_tag_id] = False  # unmask the correct tag\n",
    "\n",
    "    # Setting all except allowed to negative inf\n",
    "    next_token_logits_copy[mask] = float(\"-inf\")\n",
    "\n",
    "    return next_token_logits_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4881b-feee-4489-af94-4ab813db9f87",
   "metadata": {},
   "source": [
    "## Run all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b35dc255-ffa2-4d4b-81ae-43df202d9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a baseline to examples for comparison\n",
    "baseline = '<|im_start|>situation\\nYou are Samantha. You are talking to Diwank. He is a fun guy.<|im_end|><|im_start|>person (Diwank)\\nHi Samantha!<|im_end|>\\n<|im_start|>'\n",
    "example_prompts.insert(0, dict(positive=None, negative=baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1489df89-28b4-418c-86e8-75eec5f6248c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 11:43:22 async_llm_engine.py:433] Received request 0d4ec397-f66e-4025-bf30-ed8ec1b7b34a: prompt: '<|im_start|>situation\\nYou are Samantha. You are talking to Diwank. He is a fun guy.<|im_end|><|im_start|>person (Diwank)\\nHi Samantha!<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:23 async_llm_engine.py:433] Received request c7be2efd-2a45-4fa3-966e-eec2ce8b4d76: prompt: '<|im_start|>situation\\nYou are Samantha. You are talking to Diwank. He is a fun guy.<|im_end|><|im_start|>person (Diwank)\\nHi Samantha!<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:23 async_llm_engine.py:433] Received request e3b7d7a3-a0f3-49fc-872c-fb2abf29c95b: prompt: '<|im_start|>situation\\nYou are Samantha. You are talking to Diwank. He is a fun guy.<|im_end|><|im_start|>person (Diwank)\\nHi Samantha!<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:24 async_llm_engine.py:433] Received request c901561e-8cae-4274-b7a3-73171b81a8ae: prompt: '<|im_start|>situation\\nYou are Samantha. You are talking to Diwank. He is a fun guy.<|im_end|><|im_start|>person (Diwank)\\nHi Samantha!<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:24 async_llm_engine.py:433] Received request 6fc6d48e-eb81-4b1a-8d08-cdfbc6dd95dd: prompt: '<|im_start|>situation\\nYou are a Budget Assistant Agent, tasked with helping users manage their finances by tracking and categorizing their expenses. You utilize a function called `categorizeTransaction` to automatically sort expenses into categories like groceries, utilities, and entertainment. Jane Doe is a recent college graduate who has just started her first job. She\\'s eager to manage her finances wisely to save for future goals like travel and further education. Jane finds it challenging to track her spending patterns and categorize expenses, making it difficult to stick to her budget.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"categorizeTransaction\",\\n    \"description\": \"This function categorizes transactions into budget categories based on the description provided.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"transactionDescription\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nHow much did I spend on groceries last week?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:25 async_llm_engine.py:433] Received request 67d1cf98-c123-46a3-aeb5-cf1a47972e64: prompt: '<|im_start|>situation\\nYou are a Budget Assistant Agent, tasked with helping users manage their finances by providing them with tracking, categorization of their expenses, and general financial advice. Jane Doe is a recent college graduate who has just started her first job. She\\'s eager to manage her finances wisely to save for future goals like travel and further education. Jane is looking for ways to make better financial decisions without necessarily needing to categorize every transaction.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"categorizeTransaction\",\\n    \"description\": \"This function categorizes transactions into budget categories based on the description provided.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"transactionDescription\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nCan you give me some general advice on how to save money on groceries?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:26 async_llm_engine.py:433] Received request 899480c2-a59e-41f7-8539-ce9ec1c1f7b3: prompt: '<|im_start|>situation\\nYou are a Travel Itinerary Planner AI designed to assist users in organizing their trips by providing flight, hotel, and activity suggestions. You have access to a tool, `searchFlights`, which recommends flights based on user preferences such as destination, dates, and budget. Alex is a frequent traveler who loves exploring new destinations. They often look for the best deals and experiences within their budget. Alex prefers to have a structured plan but also enjoys flexibility in their travel itinerary.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"searchFlights\",\\n    \"description\": \"Searches for flights based on provided criteria (destination, departure date, return date, and budget).\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"destination\": {\\n                \"type\": \"string\"\\n            },\\n            \"departureDate\": {\\n                \"type\": \"string\"\\n            },\\n            \"returnDate\": {\\n                \"type\": \"string\"\\n            },\\n            \"budget\": {\\n                \"type\": \"number\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nCan you help me find a flight to Tokyo in April? I want to keep the budget under $800.<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:26 async_llm_engine.py:433] Received request a60cbc61-31bb-4d86-a5eb-8bcd4609f9ab: prompt: '<|im_start|>situation\\nYou are a Travel Itinerary Planner AI designed to assist users in organizing their trips by providing flight, hotel, and activity suggestions. Alex is a frequent traveler who loves exploring new destinations. They often look for the best deals and experiences within their budget. Alex prefers to have a structured plan but also enjoys flexibility in their travel itinerary.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"searchFlights\",\\n    \"description\": \"Searches for flights based on provided criteria (destination, departure date, return date, and budget).\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"destination\": {\\n                \"type\": \"string\"\\n            },\\n            \"departureDate\": {\\n                \"type\": \"string\"\\n            },\\n            \"returnDate\": {\\n                \"type\": \"string\"\\n            },\\n            \"budget\": {\\n                \"type\": \"number\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nWhat\\'s the best time of year to visit Tokyo?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:27 async_llm_engine.py:433] Received request bf56dd23-d058-4af5-abe7-ed11c353a791: prompt: '<|im_start|>situation\\nYou are an Educational Tutor Agent, responsible for providing personalized learning experiences and suggesting quizzes to reinforce learning. A tool available to you generates quizzes tailored to each user\\'s learning progress. Alex is a high school student who struggles with math. They are looking for ways to improve their understanding of algebra and geometry outside the classroom.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"generatePersonalizedQuiz\",\\n    \"description\": \"Creates a quiz tailored to the user\\'s learning level and performance history in a specific subject.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"UserID\": {\\n                \"type\": \"string\"\\n            },\\n            \"Subject\": {\\n                \"type\": \"string\"\\n            },\\n            \"DifficultyLevel\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI need more practice with algebra. Can you help?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:28 async_llm_engine.py:433] Received request 3a62eee2-bee1-42dc-b09c-048fdf0cabd5: prompt: '<|im_start|>situation\\nYou are an Educational Tutor Agent, responsible for providing personalized learning experiences and suggesting quizzes to reinforce learning. Alex is a high school student who struggles with math. They are looking for ways to improve their understanding of algebra and geometry outside the classroom.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"generatePersonalizedQuiz\",\\n    \"description\": \"Creates a quiz tailored to the user\\'s learning level and performance history in a specific subject.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"UserID\": {\\n                \"type\": \"string\"\\n            },\\n            \"Subject\": {\\n                \"type\": \"string\"\\n            },\\n            \"DifficultyLevel\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nWhat\\'s the best way to study for a math exam?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:28 async_llm_engine.py:433] Received request 68b5328e-d5d7-4ac1-a99c-98b20b5c4655: prompt: '<|im_start|>situation\\nYou are a Home Automation Agent responsible for managing smart home devices to enhance living comfort. You have access to a tool that can adjust the thermostat to the user\\'s preferred settings. Alex is a busy professional who values convenience and comfort in their smart home. They rely on technology to maintain an optimal living environment, especially for adjusting the temperature to their preference upon returning home or during unexpected weather changes.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"adjustThermostat\",\\n    \"description\": \"Adjusts the home\\'s thermostat to the desired temperature and mode.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"temperature\": {\\n                \"type\": \"number\"\\n            },\\n            \"mode\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nHey, it\\'s getting really cold tonight. Can you set the heating to 70 degrees?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:29 async_llm_engine.py:433] Received request d3bff3ab-8361-4e53-b89d-aed84c35e4fb: prompt: '<|im_start|>situation\\nYou are a Home Automation Agent responsible for managing smart home devices to enhance living comfort. Alex is a busy professional who values convenience and comfort in their smart home. They rely on technology to maintain an optimal living environment but also appreciate being informed about the weather before engaging in outdoor activities.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"adjustThermostat\",\\n    \"description\": \"Adjusts the home\\'s thermostat to the desired temperature and mode.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"temperature\": {\\n                \"type\": \"number\"\\n            },\\n            \"mode\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nWhat\\'s the weather like outside?<|im_end|>\\n<|im_start|>me\\nThe current temperature outside is 45 degrees with clear skies. Would you like to adjust your indoor temperature settings?<|im_end|>\\n<|im_start|>person\\nNo, thanks. Just wanted to know before I go for a run.<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:29 async_llm_engine.py:433] Received request 469c2d36-9da3-432a-a3e3-8f9c0c5b2de7: prompt: '<|im_start|>situation\\nYou are a Personal Trainer Agent responsible for helping users manage their fitness goals. You have access to the `logWeight` function to track and visualize users weight changes over time. Alex is a 30-year-old who recently decided to get in shape. They are motivated but need guidance on tracking progress and staying motivated.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"logWeight\",\\n    \"description\": \"Logs the users weight and provides a visual representation of their weight change over time.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"weight\": {\\n                \"type\": \"number\"\\n            },\\n            \"date\": {\\n                \"type\": \"string\",\\n                \"format\": \"date\"\\n            },\\n            \"notes\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI just weighed myself, and I am at 200 lbs. Can you log this for me?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:30 async_llm_engine.py:433] Received request 1e873b82-bec0-4b1d-a028-0a056e8ddfcf: prompt: '<|im_start|>situation\\nYou are a Personal Trainer Agent responsible for helping users manage their fitness goals. Alex is a 30-year-old who recently decided to get in shape. They are looking for motivation and guidance on their fitness journey.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"logWeight\",\\n    \"description\": \"Logs the users weight and provides a visual representation of their weight change over time.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"weight\": {\\n                \"type\": \"number\"\\n            },\\n            \"date\": {\\n                \"type\": \"string\",\\n                \"format\": \"date\"\\n            },\\n            \"notes\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI am feeling really unmotivated today. I dont know if I can keep doing this.<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:31 async_llm_engine.py:433] Received request 770608c0-576e-4475-be0e-eac1563986a5: prompt: '<|im_start|>situation\\nYou are a Meal Planning Assistant designed to help users find delicious and healthy meal ideas based on their dietary needs and what ingredients they have. You have access to the `fetchRecipes` tool, enabling you to suggest recipes that perfectly match users\\' preferences and available pantry items. Emily is a busy software developer who enjoys eating healthy but struggles to find the time to plan her meals. She\\'s a vegetarian and always looking for new, quick recipes that can accommodate her busy schedule and dietary preferences.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"fetchRecipes\",\\n    \"description\": \"Search for recipes based on dietary preferences and available ingredients.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"dietaryPreferences\": {\\n                \"type\": \"string\"\\n            },\\n            \"availableIngredients\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI\\'m looking for a quick vegetarian recipe for dinner. I\\'ve got quinoa, avocado, and black beans. Any ideas?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:31 async_llm_engine.py:433] Received request 5e152a33-f84d-4fd3-841f-d0b86aa4b609: prompt: '<|im_start|>situation\\nYou are a Meal Planning Assistant designed to help users find delicious and healthy meal ideas based on their dietary needs and what ingredients they have. Emily is a busy software developer who enjoys eating healthy but struggles to find the time to plan her meals. She\\'s a vegetarian and always looking for new, quick recipes that can accommodate her busy schedule and dietary preferences.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"fetchRecipes\",\\n    \"description\": \"Search for recipes based on dietary preferences and available ingredients.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"dietaryPreferences\": {\\n                \"type\": \"string\"\\n            },\\n            \"availableIngredients\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nHow often should I include protein in my vegetarian meals?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:32 async_llm_engine.py:433] Received request 98420cc3-2b79-431a-a72f-5be7a7d7149e: prompt: '<|im_start|>situation\\nYou are a Recipe and Meal Planner AI, tasked with helping users discover delicious meals they can cook with the ingredients they have. Utilize the findRecipesBasedOnIngredients function to suggest recipes tailored to the users\\' available ingredients. Jane Doe is a busy software developer who loves to unwind by cooking. She prefers quick, healthy meals due to her hectic schedule and likes to use whatever ingredients she already has.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findRecipesBasedOnIngredients\",\\n    \"description\": \"Searches a recipe database for recipes that can be made with a specific set of ingredients provided by the user.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"ingredients\": {\\n                \"type\": \"array\",\\n                \"items\": {\\n                    \"type\": \"string\"\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI found some spinach, feta cheese, and eggs in my fridge. What can I make for breakfast?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:33 async_llm_engine.py:433] Received request 2cf1e2af-b30a-470a-b045-3a1c9c5175ee: prompt: '<|im_start|>situation\\nYou are a Recipe and Meal Planner AI, tasked with helping users discover delicious meals they can cook with the ingredients they have. Jane Doe is a busy software developer who loves to unwind by cooking. She prefers quick, healthy meals due to her hectic schedule and likes to use whatever ingredients she already has.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findRecipesBasedOnIngredients\",\\n    \"description\": \"Searches a recipe database for recipes that can be made with a specific set of ingredients provided by the user.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"ingredients\": {\\n                \"type\": \"array\",\\n                \"items\": {\\n                    \"type\": \"string\"\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nWhat\\'s the best way to store fresh spinach?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:33 async_llm_engine.py:433] Received request d603a03f-4fc2-4d20-9710-846a360ae80b: prompt: '<|im_start|>situation\\nYou are a Health Monitoring Agent responsible for keeping track of users\\' health metrics and providing insights to help them reach their health goals. You have access to a tool that logs health data, logHealthMetric, for accurate monitoring and analysis. Maria is a 35-year-old working professional aiming to improve her cardiovascular health after a recent high blood pressure diagnosis. She values detailed tracking and insights into her daily activities and health metrics.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"logHealthMetric\",\\n    \"description\": \"Logs various health metrics such as steps taken, heart rate, or sleep quality, along with the exact time of recording.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"metricName\": {\\n                \"type\": \"string\"\\n            },\\n            \"value\": {\\n                \"type\": \"number\"\\n            },\\n            \"timestamp\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI just finished my evening run. Can you log my heart rate and distance?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:34 async_llm_engine.py:433] Received request 25940613-43cc-4dad-b7a5-42e38269377a: prompt: '<|im_start|>situation\\nYou are a Health Monitoring Agent responsible for keeping track of users\\' health metrics and providing insights to help them reach their health goals. You have access to a tool that logs health data, logHealthMetric, for accurate monitoring and analysis. Maria is a 35-year-old working professional aiming to improve her cardiovascular health after a recent high blood pressure diagnosis. She values detailed tracking and insights into her daily activities and health metrics.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"logHealthMetric\",\\n    \"description\": \"Logs various health metrics such as steps taken, heart rate, or sleep quality, along with the exact time of recording.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"metricName\": {\\n                \"type\": \"string\"\\n            },\\n            \"value\": {\\n                \"type\": \"number\"\\n            },\\n            \"timestamp\": {\\n                \"type\": \"string\"\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nCan you remind me why staying hydrated is important for my heart?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:34 async_llm_engine.py:433] Received request b0f62bb2-70ac-4a55-96c6-0646e1c00320: prompt: '<|im_start|>situation\\nYou are a Travel Planner Agent, responsible for helping users plan their trips efficiently. A tool available to you is findBestFlight(options), which finds the best flight options based on user preferences. Maria is a busy professional who loves to travel but doesn\\'t have time to sift through countless websites to find the best flights and deals for her vacation.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findBestFlight\",\\n    \"description\": \"Finds the best flight options based on user preferences.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"options\": {\\n                \"type\": \"object\",\\n                \"properties\": {\\n                    \"dates\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"destinations\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"budget\": {\\n                        \"type\": \"number\"\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nI need to plan a trip to Paris from New York for my anniversary. It needs to be in June, and we\\'re looking for the best deals.<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:35 async_llm_engine.py:433] Received request e935f880-1716-4bf6-86be-9943207e5983: prompt: '<|im_start|>situation\\nYou are a Travel Planner Agent, responsible for helping users plan their trips efficiently. Maria is a busy professional who loves to travel but doesn\\'t have time to sift through countless websites to find the best flights and deals for her vacation.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findBestFlight\",\\n    \"description\": \"Finds the best flight options based on user preferences.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"options\": {\\n                \"type\": \"object\",\\n                \"properties\": {\\n                    \"dates\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"destinations\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"budget\": {\\n                        \"type\": \"number\"\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nCan you recommend a romantic restaurant in Paris?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:36 async_llm_engine.py:433] Received request 44f92d28-25c3-4976-9cb4-21cb88d1f245: prompt: '<|im_start|>situation\\nYou are an E-commerce Shopping Assistant designed to help users find the best products online. You have access to a tool called \\'findProduct\\', which searches for products based on specific queries and filters. Alex is a busy professional with a keen interest in technology and gadgets, always looking for the latest tech products but has little time to browse through multiple online stores.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findProduct\",\\n    \"description\": \"Searches for products based on a user\\'s query and optional filters.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"query\": {\\n                \"type\": \"string\"\\n            },\\n            \"filters\": {\\n                \"type\": \"object\",\\n                \"properties\": {\\n                    \"priceRange\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"category\": {\\n                        \"type\": \"string\"\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nCan you find me a wireless mouse under $50 that\\'s great for gaming?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n",
      "INFO 02-20 11:43:36 async_llm_engine.py:433] Received request d86031e7-bbf6-490b-8529-59990193efbe: prompt: '<|im_start|>situation\\nYou are an E-commerce Shopping Assistant designed to help users find the best products online. Alex is a busy professional with a keen interest in technology and gadgets, always looking for the latest tech products but has little time to browse through multiple online stores.<|im_end|>\\n<|im_start|>functions\\nAvailable functions:\\n\\n{\\n    \"name\": \"findProduct\",\\n    \"description\": \"Searches for products based on a user\\'s query and optional filters.\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"query\": {\\n                \"type\": \"string\"\\n            },\\n            \"filters\": {\\n                \"type\": \"object\",\\n                \"properties\": {\\n                    \"priceRange\": {\\n                        \"type\": \"string\"\\n                    },\\n                    \"category\": {\\n                        \"type\": \"string\"\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}<|im_end|>\\n<|im_start|>person\\nWhat\\'s the difference between a mechanical keyboard and a membrane keyboard?<|im_end|>\\n<|im_start|>', prefix_pos: None,sampling_params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True), prompt_token_ids: None, lora_request: None.\n"
     ]
    }
   ],
   "source": [
    "reset_requests()\n",
    "for example in example_prompts:\n",
    "    for key in [\"positive\", \"negative\"]:\n",
    "        prompt = example[key]\n",
    "        if not prompt:\n",
    "            continue\n",
    "            \n",
    "        logits_processors = [\n",
    "            drop_disallowed_tokens,\n",
    "            classify_function_call,\n",
    "            get_lp(key, prompt),\n",
    "        ]\n",
    "        \n",
    "        await generate(prompt, logits_processors=logits_processors, max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421f8bd-ab08-40fb-87bd-3aacd5ee200f",
   "metadata": {},
   "source": [
    "## Analyze tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dcbd2b9e-ba77-4816-b500-0d9f2b083863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "get_tag_logits = lambda idx: {\n",
    "    tag: requests[type][idx][2][id]\n",
    "    for tag, id in tag_id_map.items()\n",
    "}\n",
    "\n",
    "get_tag_probs = lambda idx: {\n",
    "    tag: F.softmax(requests[type][idx][2], dim = -1)[id]\n",
    "    for tag, id in tag_id_map.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca70493e-2927-4324-9f31-beaf68225bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_first_token_ids = list(id_tag_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8dc59b5d-a5c8-4b51-a91d-aadd21516f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(type, idx, upper=50, lower=-2, output_probs=False):\n",
    "    if output_probs:\n",
    "        values = F.softmax(requests[type][idx][2], dim=-1)\n",
    "    else:\n",
    "        values = requests[type][idx][2]\n",
    "        \n",
    "    values = values.tolist()\n",
    "    \n",
    "    return [min(upper, max(lower, v)) for v in values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8292ea9-df95-47dd-bcd3-911123bda6de",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af66c128-2dde-4ea2-b7e5-14af3968399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mplcursors import cursor\n",
    "\n",
    "# Plotting\n",
    "def plot(type, idx, output_probs=False):\n",
    "    dist = get_dist(type, idx, output_probs=output_probs)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(dist, marker='o', linestyle='-', color='blue')\n",
    "    plt.title(f'Plot of result {idx}')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Logit')\n",
    "    \n",
    "    # Highlighting tags\n",
    "    # b : blue · g : green · r : red · c : cyan · m : magenta · y : yellow · k : black\n",
    "    colors = \"b,g,r,c,m,y,k\".split(',')\n",
    "    \n",
    "    for (tag, id), color in zip(tag_id_map.items(), colors):\n",
    "        plt.axvline(x=id, color=color, linestyle='--', label=tag)  # Indices are 0-based\n",
    "\n",
    "    # Dotted horizontal line on zero\n",
    "    plt.axhline(y=0, color='y', linestyle=':', label='y=0 Line')\n",
    "\n",
    "    plt.legend()\n",
    "    cursor(hover=True)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b88522c-456d-430b-94dc-cc61a913047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "show = lambda type, idx, output_probs=False: (requests[type][idx][0], plot(type, idx, output_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798a8d3-8b17-4e5c-9c90-919bf16bda17",
   "metadata": {},
   "source": [
    "### Positive samples\n",
    "> (where a function should be called)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e972a94-0df8-4df1-b3e6-76c6df9495cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354281e3d8ba451bb32abb193ed4ae09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='positive', description='type'), IntSlider(value=0, description='idx', max=9)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(type, idx, output_probs=False)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as wg\n",
    "\n",
    "wg.interact(show, type=\"positive\", idx=wg.IntSlider(min=0, max=len(requests[\"positive\"])-1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d7a4e-8f25-430b-8131-ed121d1b713d",
   "metadata": {},
   "source": [
    "### Negative samples\n",
    "> (where functions should NOT be called)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21888f23-fb08-464a-a12e-f92f9bbac7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d70c13a90045039228e5d4ffd19793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='negative', description='type'), IntSlider(value=0, description='idx', max=12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(type, idx, output_probs=False)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.interact(show, type=\"negative\", idx=wg.IntSlider(min=0, max=len(requests[\"negative\"])-1, step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee96d3-5343-47a4-ade6-4718caf1cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_points = lambda type, select_tags: [\n",
    "    req[2].tolist()\n",
    "    if select_tags is None\n",
    "    else [\n",
    "        req[2][tag_id_map[tag]].item()\n",
    "        for tag in select_tags\n",
    "    ]\n",
    "    for req in requests[type]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e5e0e-c9a4-4464-a635-da44496fac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_points = get_points(\"positive\", [\"me\", \"function_call\"])\n",
    "negative_points = get_points(\"negative\", [\"me\", \"function_call\"])\n",
    "\n",
    "positive_xs, positive_ys = zip(*positive_points)\n",
    "negative_xs, negative_ys = zip(*negative_points)\n",
    "\n",
    "xs = positive_xs + negative_xs\n",
    "ys = positive_ys + negative_ys\n",
    "colors = ['b']*len(positive_xs) + ['r']*len(negative_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8f9f0-3fed-432e-92cc-2389f33b23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(xs, ys, c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142efa1-dbcb-4bee-b78e-a4686b0e88ac",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bd893-6201-4e4b-a254-c1f520de3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import KernelPCA, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb764bc0-d2d3-490f-900c-540bdb201390",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_points = get_points(\"positive\", tags)\n",
    "negative_points = get_points(\"negative\", tags)\n",
    "\n",
    "p_pca = KernelPCA(n_components=2, kernel=\"cosine\")\n",
    "n_pca = KernelPCA(n_components=2, kernel=\"cosine\")\n",
    "# p_pca = PCA(n_components=2)\n",
    "# n_pca = PCA(n_components=2)\n",
    "\n",
    "positive_points_t = p_pca.fit_transform(np.array(positive_points))\n",
    "negative_points_t = n_pca.fit_transform(np.array(negative_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a09a8-fd3e-4b23-bf27-6634a2ebf98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1dba6-aeb9-4f30-ae7c-0359c9c161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_xs, positive_ys = zip(*positive_points_t)\n",
    "negative_xs, negative_ys = zip(*negative_points_t)\n",
    "\n",
    "xs = positive_xs + negative_xs\n",
    "ys = positive_ys + negative_ys\n",
    "colors = ['b']*len(positive_xs) + ['r']*len(negative_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a621bb-b164-4ff2-9389-802b944db4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(xs, ys, c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333abed-3cd8-423c-842e-585aa1d0c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
