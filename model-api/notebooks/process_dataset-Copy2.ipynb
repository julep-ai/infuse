{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80aa2ec0-bc54-478f-96a8-746c7b1be871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2cf2f-2041-4cd8-accc-759686c7a65f",
   "metadata": {},
   "source": [
    "## Sample Functions (generated by gpt4)\n",
    "> [ChatGPT Thread](https://chat.openai.com/share/6ed2d0bb-ec35-4273-85b8-113d37db7f43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2498009-32ec-4cfa-8853-2d762d69ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_functions = dict(\n",
    "    personal_trainer={ \"name\": \"logWeight\", \"description\": \"Logs the users weight and provides a visual representation of their weight change over time.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"weight\": { \"type\": \"number\" }, \"date\": { \"type\": \"string\", \"format\": \"date\" }, \"notes\": { \"type\": \"string\" } } } },\n",
    "    budget_assistant={\n",
    "        \"name\": \"categorizeTransaction\",\n",
    "        \"description\": \"This function categorizes transactions into budget categories based on the description provided.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"transactionDescription\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    home_agent={\n",
    "        \"name\": \"adjustThermostat\",\n",
    "        \"description\": \"Adjusts the home's thermostat to the desired temperature and mode.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"temperature\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"mode\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    meal_planner={\n",
    "        \"name\": \"fetchRecipes\",\n",
    "        \"description\": \"Search for recipes based on dietary preferences and available ingredients.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"dietaryPreferences\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"availableIngredients\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    educational_tutor={\n",
    "        \"name\": \"generatePersonalizedQuiz\",\n",
    "        \"description\": \"Creates a quiz tailored to the user's learning level and performance history in a specific subject.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"UserID\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"Subject\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"DifficultyLevel\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    travel_planner={\n",
    "        \"name\": \"searchFlights\",\n",
    "        \"description\": \"Searches for flights based on provided criteria (destination, departure date, return date, and budget).\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"destination\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"departureDate\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"returnDate\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"budget\": {\n",
    "                    \"type\": \"number\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    meal_planner_2={\n",
    "        \"name\": \"findRecipesBasedOnIngredients\",\n",
    "        \"description\": \"Searches a recipe database for recipes that can be made with a specific set of ingredients provided by the user.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"ingredients\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    travel_planner_2={\n",
    "        \"name\": \"findBestFlight\",\n",
    "        \"description\": \"Finds the best flight options based on user preferences.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"options\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"dates\": {\"type\": \"string\"},\n",
    "                        \"destinations\": {\"type\": \"string\"},\n",
    "                        \"budget\": {\"type\": \"number\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    health_monitor={\n",
    "        \"name\": \"logHealthMetric\",\n",
    "        \"description\": \"Logs various health metrics such as steps taken, heart rate, or sleep quality, along with the exact time of recording.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"metricName\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"value\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"timestamp\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    ecommerce_assistant={\n",
    "        \"name\": \"findProduct\",\n",
    "        \"description\": \"Searches for products based on a user's query and optional filters.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"filters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"priceRange\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"category\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eb2fd-49c9-49e2-8406-bff4fc7b7f62",
   "metadata": {},
   "source": [
    "## Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41efaf92-9ae2-4756-a894-40dcd04c48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"togethercomputer/glaive-function-calling-v2-formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baed17a9-747b-4188-8644-05f850e3f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47eae24a-648d-4efe-934d-40010a45ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def convert_tools_to_functions(row):\n",
    "    tools = json.loads(row[\"tools\"])\n",
    "\n",
    "    # Get functions\n",
    "    functions = (\n",
    "        # [tool[\"function\"] for tool in tools]\n",
    "        # if tools else\n",
    "        random.sample(list(sample_functions.values()), 1)\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        functions='[]', # json.dumps(functions),  # hf datasets cant hold arbitrary types\n",
    "        use_function=False\n",
    "    )\n",
    "\n",
    "ds = ds.map(convert_tools_to_functions).remove_columns(\"tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f61f791-c44d-4165-bf5f-1abbc10e5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_system_message(row):\n",
    "    situation_content = \"You are a helpful assistant with access to one or more tools. Use them only if required to fulfill a user's request.\"\n",
    "    messages = json.loads(row[\"messages\"])\n",
    "\n",
    "    # Sanity check\n",
    "    assert messages[0][\"role\"] == \"system\"\n",
    "    \n",
    "    # Replace system message\n",
    "    messages[0] = dict(\n",
    "        role=\"system\",\n",
    "        name=\"situation\",\n",
    "        content=situation_content,\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        messages=messages[:2],  # Only keep system and user messages\n",
    "    )\n",
    "\n",
    "ds = ds.map(replace_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e65bb5-da29-4808-87b6-cc9e503284bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.filter(lambda row: all(msg[\"content\"] for msg in row[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3312b84-46f8-4c90-b8df-27582d986a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_api.conversion.conversions import to_prompt, parse_message\n",
    "from model_api.conversion.datatypes import ChatMLMessage\n",
    "from model_api.protocol import FunctionDef\n",
    "\n",
    "# Convert to prompts\n",
    "convert_to_prompt = lambda row: dict(\n",
    "    prompt=to_prompt(\n",
    "        messages=[\n",
    "            ChatMLMessage(**message)\n",
    "            for message in row[\"messages\"]\n",
    "        ],\n",
    "        functions=[\n",
    "            FunctionDef(**fn)\n",
    "            for fn in json.loads(row[\"functions\"])\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "ds = ds.map(convert_to_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e41df0-9095-402c-8e1b-b0ecc8f7748c",
   "metadata": {},
   "source": [
    "## Start engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174aa0cc-8697-44c0-a8dc-d5beb7ad39d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AsyncEngineArgs(model='julep-ai/samantha-1-turbo', tokenizer='julep-ai/samantha-1-turbo', tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', seed=0, max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, block_size=16, swap_space=4, gpu_memory_utilization=0.98, max_num_batched_tokens=None, max_num_seqs=256, max_paddings=256, disable_log_stats=False, revision=None, tokenizer_revision=None, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, max_cpu_loras=None, engine_use_ray=False, disable_log_requests=False, max_log_len=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vllm import AsyncLLMEngine, AsyncEngineArgs\n",
    "\n",
    "engine_args = AsyncEngineArgs(\n",
    "    model=\"julep-ai/samantha-1-turbo\",\n",
    "    dtype=\"bfloat16\",\n",
    "    enforce_eager=False,\n",
    "    tensor_parallel_size=2,\n",
    "    swap_space=4,  # GiB\n",
    "    gpu_memory_utilization=0.98,\n",
    "    max_num_seqs=256,\n",
    ")\n",
    "\n",
    "\n",
    "engine_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28cee360-ef57-4610-85a9-21b4981c8d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 15:57:03,178\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 15:57:04 llm_engine.py:72] Initializing an LLM engine with config: model='julep-ai/samantha-1-turbo', tokenizer='julep-ai/samantha-1-turbo', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-20 15:57:10 custom_all_reduce.py:125] NVLink detection failed with message \"Not Supported\". This is normal if your machine has no NVLink equipped\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:10 custom_all_reduce.py:125] NVLink detection failed with message \"Not Supported\". This is normal if your machine has no NVLink equipped\n",
      "INFO 02-20 15:57:12 weight_utils.py:164] Using model weights format ['*.bin']\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:12 weight_utils.py:164] Using model weights format ['*.bin']\n",
      "INFO 02-20 15:57:29 llm_engine.py:322] # GPU blocks: 5169, # CPU blocks: 4096\n",
      "INFO 02-20 15:57:30 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-20 15:57:30 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:30 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:30 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-20 15:57:37 custom_all_reduce.py:199] Registering 2275 cuda graph addresses\n",
      "INFO 02-20 15:57:37 model_runner.py:698] Graph capturing finished in 7 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:37 custom_all_reduce.py:199] Registering 2275 cuda graph addresses\n",
      "\u001b[36m(RayWorkerVllm pid=289234)\u001b[0m INFO 02-20 15:57:37 model_runner.py:698] Graph capturing finished in 7 secs.\n"
     ]
    }
   ],
   "source": [
    "engine = AsyncLLMEngine.from_engine_args(engine_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa04bf-8121-4262-a8e4-e8f3aed05153",
   "metadata": {},
   "source": [
    "## Tokenize prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbaba94-bcb3-4c81-976c-7051200fbb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a3c8b9bf5b4debbda6c0b2ed70a2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111944 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bb41295a1543e9ab2d7e63a1c9e7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = engine.engine.tokenizer.tokenizer\n",
    "\n",
    "ds = ds.map(\n",
    "    lambda row: dict(\n",
    "        prompt_token_ids=tokenizer.encode(row[\"prompt\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "# )[\"train\"][0][\"prompt_token_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a215c-edef-407f-a31a-6af425dac9cb",
   "metadata": {},
   "source": [
    "## Prepare generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91773a5-a70f-488e-ad28-fc8223e80a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from vllm.sampling_params import SamplingParams\n",
    "\n",
    "def prep_generator(\n",
    "    prompt_token_ids,\n",
    "    temperature=0,\n",
    "    max_tokens=1,\n",
    "    logits_processors=[],\n",
    "    **sampling_kwargs,\n",
    "):\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        logits_processors=logits_processors,\n",
    "        **sampling_kwargs,\n",
    "    )\n",
    "    \n",
    "    res_generator = engine.generate(\n",
    "        sampling_params=sampling_params,\n",
    "        request_id=uuid4(),\n",
    "        prompt=None,\n",
    "        prompt_token_ids=prompt_token_ids,\n",
    "    )\n",
    "\n",
    "    return res_generator\n",
    "\n",
    "async def generate(\n",
    "    prompt_token_ids,\n",
    "    **sampling_kwargs,\n",
    "):\n",
    "    res_generator = prep_generator(prompt_token_ids, **sampling_kwargs)\n",
    "    final_res = None\n",
    "\n",
    "    async for res in res_generator:\n",
    "        final_res = res\n",
    "    \n",
    "    return final_res\n",
    "\n",
    "def generate_no_wait(\n",
    "    prompt_token_ids,\n",
    "    **sampling_kwargs,\n",
    "):\n",
    "    res_generator = prep_generator(prompt_token_ids, **sampling_kwargs)\n",
    "\n",
    "    async def waiter():\n",
    "        final_res = None\n",
    "        \n",
    "        async for res in res_generator:\n",
    "            final_res = res\n",
    "        \n",
    "        return final_res\n",
    "\n",
    "    return waiter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0248caf-b8a7-4cf2-80d4-e92e6396a39c",
   "metadata": {},
   "source": [
    "## Prep logits processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024b08d7-c0a1-4e22-99ff-038a65056b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tags \n",
    "allowed_tags = [\"me\", \"function_call\", \"thought\"]\n",
    "disallowed_tags = [\"situation\", \"person\", \"functions\", \"information\"]\n",
    "tags = allowed_tags + disallowed_tags\n",
    "\n",
    "allowed_tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in allowed_tags\n",
    "]\n",
    "\n",
    "disallowed_tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in disallowed_tags\n",
    "]\n",
    "\n",
    "tag_token_ids = [\n",
    "    tokenizer(tag, add_special_tokens=False)[\"input_ids\"]\n",
    "    for tag in tags\n",
    "]\n",
    "\n",
    "tag_id_map = {\n",
    "    tag: tag_ids[0]\n",
    "    for tag, tag_ids in zip(tags, tag_token_ids)\n",
    "}\n",
    "\n",
    "id_tag_map = {\n",
    "    id: tag\n",
    "    for tag, id in tag_id_map.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd923739-efa2-4791-bcc2-e24a457f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "requests: dict[str, tuple[str, list[int], torch.Tensor]] = dict(\n",
    "    positive=[],\n",
    "    negative=[],\n",
    ")\n",
    "\n",
    "def get_lp(type, prompt):\n",
    "    def processor(\n",
    "        previously_generated_tokens,\n",
    "        next_token_logits,\n",
    "    ):\n",
    "        assert len(previously_generated_tokens) == 0\n",
    "        \n",
    "        requests[type].append(\n",
    "            (prompt, previously_generated_tokens, next_token_logits.cpu())\n",
    "        )\n",
    "\n",
    "        return next_token_logits\n",
    "\n",
    "    return processor\n",
    "\n",
    "def reset_requests():\n",
    "    global requests\n",
    "    requests = dict(\n",
    "        positive=[],\n",
    "        negative=[],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4881b-feee-4489-af94-4ab813db9f87",
   "metadata": {},
   "source": [
    "## Run all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1489df89-28b4-418c-86e8-75eec5f6248c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b80d120a8f4c0e8ea8990ea9657135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "reset_requests()\n",
    "pending = []\n",
    "\n",
    "max_len = 15_000\n",
    "\n",
    "for i, row in enumerate(ds[\"train\"].shuffle(seed=42)):\n",
    "    if i >= max_len:\n",
    "        break\n",
    "        \n",
    "    key = \"positive\" if row[\"use_function\"] else \"negative\"\n",
    "    prompt_token_ids = row[\"prompt_token_ids\"]\n",
    "    prompt = row[\"prompt\"]\n",
    "            \n",
    "    logits_processors = [\n",
    "        get_lp(key, prompt),\n",
    "    ]\n",
    "    \n",
    "    pending.append(\n",
    "        generate_no_wait(prompt_token_ids, logits_processors=logits_processors, max_tokens=1)\n",
    "    )\n",
    "\n",
    "completed = asyncio.as_completed(pending)\n",
    "\n",
    "for future in tqdm(completed, total=max_len):\n",
    "    await future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52419c4-95c1-447f-be19-b7d7f6dcefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "with open('./processed_new_new.pickle', 'wb') as processed_file:\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(requests, processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c348f39-9735-4887-9e90-a748a2c3e278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
