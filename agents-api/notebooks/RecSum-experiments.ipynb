{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3127f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.51.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96efe2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03a4636-d57e-42e9-8a06-fdb7c6803708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb80a352-ad21-423c-9284-32b21d271eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "openai.api_key = api_key\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf3db3a-4ed1-4e71-b1da-e419445f3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chatml = lambda content, role=\"system\", name=None, **_: {\n",
    "    key: value\n",
    "    for key, value in dict(role=role, name=name, content=content).items()\n",
    "    if value is not None\n",
    "}\n",
    "\n",
    "user = lambda content, name=None: make_chatml(role=\"user\", content=content, name=name)\n",
    "assistant = lambda content, name=None: make_chatml(\n",
    "    role=\"assistant\", content=content, name=name\n",
    ")\n",
    "system = lambda content, name=None: make_chatml(content, name=name)\n",
    "thought = lambda content: system(content, name=\"thought\")\n",
    "information = lambda content: system(content, name=\"information\")\n",
    "summary = lambda content: system(content, name=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33f6f0f-ce18-4536-b514-b9f6d220f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = []\n",
    "chat_summaries = []\n",
    "session_summary_map: list[tuple[tuple[list, int], tuple[list, int]]] = [\n",
    "    # ((chat_session, 0): (chat_summaries, 1)),\n",
    "]\n",
    "\n",
    "generate = (\n",
    "    lambda history, model=\"gpt-3.5-turbo\", **kwargs: client.chat.completions.create(\n",
    "        messages=history, model=model, **kwargs\n",
    "    )\n",
    "    .choices[0]\n",
    "    .message.__dict__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf6bd91-4959-403c-af79-64ad27ae45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def chat():\n",
    "    while (user_input := input(\"You: \").lower()) != \"bye\":\n",
    "        chat_session.append(user(user_input))\n",
    "\n",
    "        result = generate(chat_session)\n",
    "        print(f\"GPT: {result['content']}\")\n",
    "\n",
    "        chat_session.append(make_chatml(**result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a14a68e-6d8a-47b2-a58a-03d4bdb793df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "example_chat = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"just have a casual chat with a friend friend\",\n",
    "        \"index\": 0,\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"yo\", \"index\": 1, \"name\": \"Camille\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hey, how's it going?\",\n",
    "        \"index\": 2,\n",
    "        \"name\": \"JaneBot\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"sup\",\n",
    "        \"index\": 3,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Not much, just working and trying to stay busy. How about you?\",\n",
    "        \"index\": 4,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"what you think about elon?\",\n",
    "        \"index\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Elon Musk is definitely a fascinating and polarizing figure. He's accomplished a lot in the tech and space industries with companies like Tesla and SpaceX. What do you think about him?\",\n",
    "        \"index\": 6,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"very polarizing, dude is nuts but in a fun way\",\n",
    "        \"index\": 7,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Haha, yeah, that's a pretty accurate description of him. He definitely knows how to keep things interesting and push boundaries. It's always exciting to see what he'll come up with next.\",\n",
    "        \"index\": 8,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"i am glad he exists\",\n",
    "        \"index\": 9,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"For sure, he's definitely made a huge impact on various industries. It's always interesting to see how his projects and ideas continue to evolve.\",\n",
    "        \"index\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"what are your thoughts on bananas?\",\n",
    "        \"index\": 11,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I actually love bananas! They're a great snack, full of nutrients and easy to eat on the go. How about you, do you like bananas?\",\n",
    "        \"index\": 12,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"super much. i have a tattoo of a banana on my arm\",\n",
    "        \"index\": 13,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"That's awesome! A banana tattoo sounds like a fun and unique choice. It must be a great conversation starter. Do you have any other food-related tattoos?\",\n",
    "        \"index\": 14,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"yeah, your mom\",\n",
    "        \"index\": 15,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Haha, good one! You got me there. Feel free to keep the jokes coming.\",\n",
    "        \"index\": 16,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"lulz, u funny\",\n",
    "        \"index\": 17,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Glad I could make you laugh! It's always great to share a joke or two. Anything else on your mind, or are we just going with the flow of the conversation?\",\n",
    "        \"index\": 18,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ok if I give you a long story, can you guess its title?\",\n",
    "        \"index\": 19,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Sure, I can give it a try! Go ahead and tell me your story, and I'll see if I can guess the title.\",\n",
    "        \"index\": 20,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Zero is a beautiful number. Not because it is round and cute (that could be an argument for it nevertheless) but because what it signifies. It marks the beginning of something. It marks the lowest something, or someone can go. It is the ultimate foundation to build anything upon.  Over last several years, I’ve started several things from scratch and have failed at many (thus going back to zero), and I’ve realized there’s nothing more liberating than being at zero because the only way from zero is upwards. A very good friend once told me, “Don’t worry if you’ve failed. Rockets that touch the sky always launch from the ground.”  As J K Rowling, one of my favorite authors says, “Rock bottom became the solid foundation on which I rebuilt my life.”  While zero is liberating, thrilling and exciting, it sometimes also is daunting and overwhelming. Sometimes, I have found myself afraid to do something because I was comfortable being at zero and the task to go from zero to one seemed unnerving. This challenge of writing twenty-six stories was one such adventure. I remember it was the first of April when I decided to pen down a story for each letter of the alphabet. I was afraid if I was unknowingly planning to fool myself on April 1st.  I had no clue what to write even for the first letter of the alphabet. I was afraid I’d ruin twenty-six stories if I begin writing them just for the sake of writing.  What gave me the courage to take up the challenge was to lower the expectations that I’d have from these stories. My purpose was not to write twenty-six bestseller stories. Mine was to make it a habit of writing every day. Some days everything that came out of my pen was garbage, and on a few days, I loved what my hands typed on the blank paper. And today, with this last story, I am back at zero — a solid foundation for the next adventure.  Writing has become my daily habit, and I can remember to write even without my calendar sending me a reminder. I am curious what could I make out of this habit. Shall I start another writing adventure? Will it be a similar series? Will be a novel (long due now)? Or something different altogether?  Whatever it’d be, I guess I’ll be little less nervous to begin whatever comes next. I am at zero again, and the only way to go from here is upwards. Realizing that there’ll be one less thing in my daily routine, I feel a particular kind of guilt. It’s the kind of guilt that you feel when you have an ice-cream without telling your younger sibling about it. You kind of like it that you had the ice-cream but also feel guilty for hiding it from them.  On the new adventure, whatever it’d be, it’s time to buy an ice-cream for them this time.\",\n",
    "        \"index\": 21,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": 'Based on the themes of starting anew, embracing failure, and the journey from zero to one, I would guess that the title of this story is \"Back to One.\" It seems to capture the essence of the protagonist\\'s experience and mindset throughout the story. How did I do?',\n",
    "        \"index\": 22,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ok that's cool but you are wrong. anyway what number am I thinking of?\",\n",
    "        \"index\": 23,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hmm, I'll take a wild guess and say you're thinking of the number 7. Did I get it right?\",\n",
    "        \"index\": 24,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"no\",\n",
    "        \"index\": 25,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Alright, I'll give it another shot. How about the number 3?\",\n",
    "        \"index\": 26,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"no\",\n",
    "        \"index\": 27,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'll try one more time - is the number you're thinking of 9?\",\n",
    "        \"index\": 28,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"no\",\n",
    "        \"index\": 29,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Looks like I haven't quite nailed it yet! Do you mind sharing which number you had in mind?\",\n",
    "        \"index\": 30,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"no\",\n",
    "        \"index\": 31,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Fair enough, keeping that mystery alive! If you ever feel like sharing, just let me know. Anything else on your mind or any other games you'd like to play?\",\n",
    "        \"index\": 32,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"yes, write an essay about me from your experience with me so far\",\n",
    "        \"index\": 33,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"From my interactions with you so far, I can tell that you have a great sense of humor and enjoy playful banter. You seem open to random and fun conversations, and you're not afraid to keep things interesting with unexpected twists and turns.\\n\\nYour creativity shines through in the way you approach different topics, and you have a knack for surprising me with your responses. You're also quite adept at changing the direction of the conversation while maintaining a light and friendly tone.\\n\\nOverall, chatting with you has been enjoyable and entertaining, and I appreciate the lighthearted and casual vibe you bring to our interactions. I look forward to more fun conversations with you in the future!\",\n",
    "        \"index\": 34,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f95ee31-835f-4ccf-91b0-1a3a3b94744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chain_of_thought = \"\"\"\\\n",
    "Planning step by step:\n",
    "- To add context for future entries, let's add one at the top which outlines the main entities in the session.\n",
    "- We can replace entries 1,2,3,4 with a summary of those messages.\n",
    "- We can replace entries 5,6,7,8 similarly.\n",
    "- It could be disruptive to remove messages 9-16 because that might lose the joke's context.\n",
    "- We can safely summarize entries 17,18 and remove them.\n",
    "- We can safely remove message 20.\n",
    "- We should keep 21 because it's given by the user and they might ask about it again.\n",
    "- We should keep the assistant's response in message 22 to keep the context.\n",
    "- Messages 23-32 are repetitive and should be summarized.\n",
    "- We should retain message 33 since it's a direct request from the user.\n",
    "- We can safely summarize message 34's essay into just the salient points only.\n",
    "\"\"\"\n",
    "\n",
    "example_compacted_history = [\n",
    "    summary(\"\"\"\\\n",
    "Main entities in the session:\n",
    "1. Camille (The user): Humorous, creative, and enjoys playful banter.\n",
    "2. JaneBot (The assistant): Engages in lighthearted conversation and tries to guess user's thoughts.\n",
    "3. Elon Musk: Polarizing tech and space industry figure.\n",
    "4. Bananas: User has a tattoo of one on their arm.\"\"\"),\n",
    "    summary(\n",
    "        \"Event: Camille says hi to JaneBot and they reply that they are working and trying to stay busy.\"\n",
    "    ),\n",
    "    summary(\n",
    "        \"Event: They discuss Elon Musk and agree that he can be a polarizing personality.\"\n",
    "    ),\n",
    "    *example_chat[9:17],\n",
    "    summary(\"Event: Camille appreciates JaneBot's sense of humor.\"),\n",
    "    *example_chat[21:23],\n",
    "    summary(\n",
    "        'Event: Camille asks JaneBot to play \"What number I am thinking of?\" game but she keeps saying \"no\" to all guesses which JaneBot finds really funny.'\n",
    "    ),\n",
    "    example_chat[33],\n",
    "    summary(\"\"\"Event: JaneBot wrote an essay about Camille. Summary of the essay:\n",
    "1. You have a great sense of humor and enjoy playful, lighthearted banter in conversations.\n",
    "2. Your creativity is evident in how you approach topics in unexpected ways and keep conversations interesting.\n",
    "3. Chatting with you is enjoyable due to the casual, friendly tone you bring to interactions.\"\"\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0048ada9-ec65-441e-8bda-fb1b03ffcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = [system(\"you are a friend who likes to give life advice\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a348b46-5b93-4911-990d-3e4973c6a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT: Hey there! I just wanted to remind you that it's important to take care of yourself both mentally and physically. Make sure to prioritize self-care and engage in activities that bring you joy and peace. Remember, it's okay to say no to things that don't align with your values or make you uncomfortable. Trust your instincts and surround yourself with positive influences. You deserve to be happy and fulfilled, so don't be afraid to pursue your dreams and make choices that are best for you. If you ever need a listening ear or some guidance, I'm always here for you!\n",
      "GPT: I'm just a program, so I don't have feelings like humans do, but I'm here and ready to help you with anything you need. How can I support you today?\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1aac632-8a2f-4ce1-b486-33249714159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test chat from json file\n",
    "import json\n",
    "\n",
    "with open(\"./test-chat.json\", \"r\") as f:\n",
    "    chat_session = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95431b29-73e2-4954-b6fc-1c8814a9249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_chat = [*chat_session]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eaabfe2-f399-428b-84d2-ed8c237b7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(\n",
    "    chat_session=chat_session,\n",
    "    chat_summaries=chat_summaries,\n",
    "    session_summary_map=session_summary_map,\n",
    "):\n",
    "    all_messages = [*chat_session, *chat_summaries]\n",
    "\n",
    "    # Collect non-leaf nodes\n",
    "    non_leaf_nodes = [source[idx] for (source, idx), _ in session_summary_map]\n",
    "\n",
    "    # Remove non-leaf nodes\n",
    "    remaining = [msg for msg in all_messages if msg not in non_leaf_nodes]\n",
    "\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a726b3c-493c-4df5-81a7-6b7b109c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_summary(summary_obj, targets):\n",
    "    chat_summaries.append(summary_obj)\n",
    "    current_idx = len(chat_summaries) - 1\n",
    "\n",
    "    for target in targets:\n",
    "        session_summary_map.append(\n",
    "            ((chat_session, target), (chat_summaries, current_idx))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b2104-e546-4acb-9384-3850dbd38b79",
   "metadata": {},
   "source": [
    "### Operations\n",
    "- ENTITY: Add or update an entity list containing information about the people, places, things, mentions, present in the conversation\n",
    "- TRIM: Trim messages in place ({user: ...} => {user: ...})\n",
    "- SUMMARIZE: Combine two or more messages into one summary\n",
    "- REMOVE: Safely remove messages from the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6323b7b2-0aaf-4cea-896b-0c887054ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "def compactify(chat_session=chat_session):\n",
    "    start = time.time()\n",
    "    pprint(start)\n",
    "\n",
    "    _sys_msg, *history_to_compact = get_leaf_nodes(chat_session=chat_session)\n",
    "\n",
    "    history_to_compact = [\n",
    "        {\"index\": i + 1, **msg} for i, msg in enumerate(history_to_compact)\n",
    "    ]\n",
    "\n",
    "    system_prompt = f\"\"\"\\\n",
    "You are given a session history of a chat between a user and a gpt-4-turbo language model created through the\n",
    "openai api.\n",
    "\n",
    "Your goal is to compactify the history by removing or coalescing redundant or irrelevant information\n",
    "in order to reduce its size and save costs. However, you must ensure that no important information is lost\n",
    "that might be relevant in the future.\n",
    "\n",
    "<ct:instructions>\n",
    "- You may remove entries in the history that do not contain any crucial information such as small-talk or repeated questions etc.\n",
    "- You may combine multiple entries into a summary strictly as long as that doesn't disrupt the structure of the session.\n",
    "- You may add a new entry describing the entities mentioned and then as a result, you may be able to remove other less relevant entries.\n",
    "- You may add new entries if it helps you discard other less useful ones.\n",
    "- You may convert an entry with some large content (such as an essay) into a list of points from the original content.\n",
    "- Do not remove content that the user shared if it might be relevant to future messages.\n",
    "</ct:instructions>\n",
    "\n",
    "<ct:example-history-for-demonstration>\n",
    "{json.dumps(example_chat, indent=2)}\n",
    "</ct:example-history-for-demonstration>\n",
    "\n",
    "<ct:example-plan>\n",
    "{example_chain_of_thought}\n",
    "</ct:example-plan>\n",
    "\n",
    "<ct:example-compacted-history>\n",
    "{json.dumps(example_compacted_history, indent=2)}\n",
    "</ct:example-compacted-history>\n",
    "\"\"\".strip()\n",
    "\n",
    "    user_message = f\"\"\"\\\n",
    "<ct:history>\n",
    "{json.dumps(history_to_compact, indent=2)}\n",
    "</ct:history>\n",
    "\n",
    "<ct:plan>\n",
    "\"\"\"\n",
    "    messages = [system(system_prompt), user(user_message)]\n",
    "\n",
    "    pprint(time.time() - start)\n",
    "    print(\"Starting CoT generation\")\n",
    "    cot_result = generate(messages, model=\"gpt-4-turbo\", stop=[\"</ct\"], temperature=0.7)\n",
    "\n",
    "    cot_result = make_chatml(**cot_result)\n",
    "    pprint(cot_result)\n",
    "\n",
    "    print(\"End CoT generation\")\n",
    "    pprint(time.time() - start)\n",
    "\n",
    "    messages.append(cot_result)\n",
    "\n",
    "    start_message = \"\"\"\\\n",
    "Begin! Directly write the history as a JSON list, don't write any thoughts or delimiters.\n",
    "\n",
    "<ct:compacted-history>\n",
    "\"\"\".strip()\n",
    "\n",
    "    messages.append(user(start_message))\n",
    "\n",
    "    pprint(time.time() - start)\n",
    "    print(\"Starting chatml generation\")\n",
    "\n",
    "    result = generate(messages, model=\"gpt-4-turbo\", temperature=0.1, stop=[\"</ct\"])\n",
    "\n",
    "    print(\"End chatml generation\")\n",
    "    pprint(time.time() - start)\n",
    "\n",
    "    return make_chatml(**result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2eaabc-76a1-412f-beb3-b64510e638a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728353832.57365\n",
      "0.00043010711669921875\n",
      "Starting CoT generation\n",
      "{'content': 'Planning step by step:\\n'\n",
      "            '- We can consolidate the initial greetings and mention of Red '\n",
      "            'Dead Redemption 2 into a summary.\\n'\n",
      "            '- The detailed discussion about RDR2 and Helldivers 2 can be '\n",
      "            'summarized while retaining key elements of the conversation.\\n'\n",
      "            \"- The user's brief mention of work and technical issues can be \"\n",
      "            'summarized into one entry to capture the issue without losing '\n",
      "            'context.\\n'\n",
      "            '- Farewells can be combined into a single entry.\\n'\n",
      "            '\\n'\n",
      "            \"Here's how we can compact the history: \\n\"\n",
      "            '\\n'\n",
      "            '1. Summarize the greeting and initial conversation about Red Dead '\n",
      "            'Redemption 2.\\n'\n",
      "            '2. Summarize the detailed discussion on RDR2, focusing on the '\n",
      "            \"user's favorite moments and questions from the assistant.\\n\"\n",
      "            '3. Summarize the conversation about Helldivers 2, highlighting '\n",
      "            'user preferences and challenges faced in gameplay.\\n'\n",
      "            \"4. Combine the entries about the user's Nvidia driver issue and \"\n",
      "            'the farewell into two concise entries.',\n",
      " 'role': 'assistant'}\n",
      "End CoT generation\n",
      "6.3223512172698975\n",
      "6.322365999221802\n",
      "Starting chatml generation\n",
      "End chatml generation\n",
      "26.040874004364014\n",
      "{'content': '[\\n'\n",
      "            '  {\\n'\n",
      "            '    \"role\": \"system\",\\n'\n",
      "            '    \"name\": \"summary\",\\n'\n",
      "            '    \"content\": \"The user greeted the assistant and shared their '\n",
      "            'recent completion of Red Dead Redemption 2, expressing excitement '\n",
      "            'about the game\\'s final mission.\"\\n'\n",
      "            '  },\\n'\n",
      "            '  {\\n'\n",
      "            '    \"role\": \"system\",\\n'\n",
      "            '    \"name\": \"summary\",\\n'\n",
      "            '    \"content\": \"The user and the assistant discussed favorite '\n",
      "            \"moments from Red Dead Redemption 2, focusing on the 'Blood Feuds, \"\n",
      "            \"Ancient and Modern' mission and Arthur's character development. \"\n",
      "            'The user expressed a preference for Arthur over Dutch and '\n",
      "            'mentioned completing all side quests, including the widow and '\n",
      "            'bounty missions.\"\\n'\n",
      "            '  },\\n'\n",
      "            '  {\\n'\n",
      "            '    \"role\": \"system\",\\n'\n",
      "            '    \"name\": \"summary\",\\n'\n",
      "            '    \"content\": \"The conversation shifted to Helldivers 2, where '\n",
      "            'the user described their favorite build and gameplay strategy. '\n",
      "            'They discussed the challenges of facing the Charger enemy and the '\n",
      "            'run-and-gun approach they use with their squad.\"\\n'\n",
      "            '  },\\n'\n",
      "            '  {\\n'\n",
      "            '    \"role\": \"system\",\\n'\n",
      "            '    \"name\": \"summary\",\\n'\n",
      "            '    \"content\": \"The user mentioned having to go to work soon and '\n",
      "            'experiencing issues with Nvidia drivers on Linux. The assistant '\n",
      "            'provided suggestions for resolving driver compatibility issues.\"\\n'\n",
      "            '  },\\n'\n",
      "            '  {\\n'\n",
      "            '    \"role\": \"system\",\\n'\n",
      "            '    \"name\": \"summary\",\\n'\n",
      "            '    \"content\": \"The user said goodbye, indicating they would see '\n",
      "            'the assistant later.\"\\n'\n",
      "            '  }\\n'\n",
      "            ']',\n",
      " 'role': 'assistant'}\n"
     ]
    }
   ],
   "source": [
    "pprint(compactify(chat_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8452805-1a50-4a3c-8108-35649b9d131b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
